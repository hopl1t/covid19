{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "# plt.matplotlib.rcParams.update({'font.size': 50})\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'   \n",
    "plt.rcParams[\"patch.force_edgecolor\"] = False\n",
    "plt.rc('figure', titlesize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_PATH = '../augmented_datasets/pickles/hopkins_confirmed_for_regression0904.pkl'\n",
    "OUTPUT_TREE_PATH = '../products/decision_tree/decision_tree_{0}.dot'\n",
    "MAX_DT_DEPTH = 5\n",
    "OUTLIER_QUARTILES = (0.02, 0.98) # Min, max quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import tree, metrics\n",
    "\n",
    "def train_test_split(X, n_splits=5):\n",
    "    '''\n",
    "    Splits rows into training indices and test indices.\n",
    "    :param X: numpy array of training data, e.g.  np.array([[1, 2], [3, 4], [1, 2], [3, 4]]) - each sample has two features\n",
    "    :return: Returns indices of rows for train and test for n_splits. e.g. n_splits=2: \n",
    "    train_folds = [[0,2,3], [1,2,3]] test_folds = [[1], [0]] \n",
    "    '''\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, random_state=2346, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    train_folds, test_folds = [], []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_folds.append(train_index)\n",
    "        test_folds.append(test_index)\n",
    "    \n",
    "    return train_folds, test_folds\n",
    "\n",
    "\n",
    "def decision_tree_train(X_train, y_train):\n",
    "    dt = tree.DecisionTreeRegressor(max_depth=MAX_DT_DEPTH)\n",
    "    trained_model = dt.fit(X_train, y_train)\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def linear_regression_train(X_train, y_train):\n",
    "    regr = sklearn.linear_model.LinearRegression()\n",
    "    trained_model = regr.fit(X_train, y_train)\n",
    "    return trained_model\n",
    "\n",
    "def remove_outlier(df, range_, columns):\n",
    "    low = range_[0]\n",
    "    high = range_[1]\n",
    "    qnt = df.quantile([low, high])\n",
    "    data = df.copy()\n",
    "    for col in list(columns):\n",
    "        data[col] = \\\n",
    "            data[(data[col] > qnt.loc[low, col]) &\\\n",
    "               (data[col] < qnt.loc[high, col])][col]\n",
    "    return data.dropna()\n",
    "\n",
    "def regression(data_, feature_cols, label_cols, outlier_quartiles=(0.02, 0.98)):\n",
    "    arrays = [[1,1,1,2,2,2,3,3,3,4,4,4,5,5,5],\\\n",
    "              ['test','train','naive','test','train','naive','test','train',\\\n",
    "               'naive','test','train','naive','test','train','naive']]\n",
    "    idx = pd.MultiIndex.from_arrays(arrays, names=('run', 'mse'))\n",
    "    regr_rslt = pd.DataFrame(index=idx)\n",
    "    for col in label_cols:\n",
    "        regr_rslt[col] = np.nan\n",
    "    summary = pd.DataFrame(\n",
    "                          {col: np.nan for col in label_cols},\n",
    "                          index=['avg(naive - test)', 'avg(naive - train)']\n",
    "                          )\n",
    "    model_fn = linear_regression_train\n",
    "    metric_fn = metrics.mean_squared_error\n",
    "\n",
    "    for label_col in label_cols:\n",
    "        data = data_[data_[label_col] > 0].copy()\n",
    "        data = remove_outlier(data, outlier_quartiles, [label_col, 'avg_interval_tmp'])\n",
    "        len(data)\n",
    "\n",
    "        X, y = np.array(data[feature_cols]), np.array(data[[label_col]])\n",
    "        # Split the data into train, test for n_splits train-test rounds\n",
    "        try:\n",
    "            train_folds, test_folds = train_test_split(X, n_splits=5)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # Train-test the model for each of the n_splits:\n",
    "        for train_test_round in range(len(train_folds)):\n",
    "            train_index = train_folds[train_test_round]\n",
    "            test_index = test_folds[train_test_round]\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            regr_trained = model_fn(X_train, y_train)\n",
    "\n",
    "            # evaluate on test\n",
    "            y_pred = regr_trained.predict(X_test)\n",
    "            regr_rslt.loc[train_test_round + 1, 'test'][label_col] = metric_fn(y_test, y_pred)\n",
    "\n",
    "            # Compare to train data\n",
    "            y_pred_train = regr_trained.predict(X_train)\n",
    "            regr_rslt.loc[train_test_round + 1, 'train'][label_col] = metric_fn(y_train, y_pred_train)\n",
    "\n",
    "            # Compare to a naive mean-value model:\n",
    "            y_pred_naive = np.ndarray(y_pred.shape)\n",
    "            y_pred_naive.fill(y_train.mean())\n",
    "            regr_rslt.loc[train_test_round + 1, 'naive'][label_col] = metric_fn(y_test, y_pred_naive)\n",
    "\n",
    "    for col in regr_rslt.columns:\n",
    "        summary.loc['avg(naive - test)'][col] = (regr_rslt[col].loc[:,'naive'] - regr_rslt[col].loc[:,'test']).mean()\n",
    "        summary.loc['avg(naive - train)'][col] = (regr_rslt[col].loc[:,'naive'] - regr_rslt[col].loc[:,'train']).mean()\n",
    "\n",
    "    return summary, regr_rslt\n",
    "\n",
    "def dt(data_, feature_cols, label_cols, outlier_quartiles=(0.02, 0.98)):\n",
    "    arrays = [[1,1,1,2,2,2,3,3,3,4,4,4,5,5,5],\\\n",
    "              ['test','train','naive','test','train','naive','test','train',\\\n",
    "               'naive','test','train','naive','test','train','naive']]\n",
    "    idx = pd.MultiIndex.from_arrays(arrays, names=('run', 'mse'))\n",
    "    regr_rslt = pd.DataFrame(index=idx)\n",
    "    for col in label_cols:\n",
    "        regr_rslt[col] = np.nan\n",
    "\n",
    "    summary = pd.DataFrame(\n",
    "                          {col: np.nan for col in label_cols},\n",
    "                          index=['avg(naive - test)', 'avg(naive - train)']\n",
    "                          )\n",
    "\n",
    "    model_fn = decision_tree_train\n",
    "\n",
    "    metric_fn = metrics.mean_squared_error\n",
    "\n",
    "    for label_col in label_cols:\n",
    "        data = data_[data_[label_col] > 0].copy()\n",
    "        data = remove_outlier(data, outlier_quartiles, [label_col, 'avg_interval_tmp'])\n",
    "        len(data)\n",
    "\n",
    "        X, y = np.array(data[feature_cols]), np.array(data[[label_col]])\n",
    "        # Split the data into train, test for n_splits train-test rounds\n",
    "        try:\n",
    "            train_folds, test_folds = train_test_split(X, n_splits=5)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # Train-test the model for each of the n_splits:\n",
    "        for train_test_round in range(len(train_folds)):\n",
    "            train_index = train_folds[train_test_round]\n",
    "            test_index = test_folds[train_test_round]\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            dt_trained = model_fn(X_train, y_train)\n",
    "            if model_fn == decision_tree_train: \n",
    "                # tree.plot_tree(dt_trained, feature_names=feature_cols)\n",
    "                suffix = label_col + '_run' + str(train_test_round)\n",
    "                _ = tree.export_graphviz(dt_trained, OUTPUT_TREE_PATH.format(suffix), feature_names=feature_cols) # dot -Tpng tree.dot -o tree.png \n",
    "            # evaluate on test\n",
    "            y_pred = dt_trained.predict(X_test)\n",
    "            regr_rslt.loc[train_test_round + 1, 'test'][label_col] = metric_fn(y_test, y_pred)\n",
    "\n",
    "            # Compare to train data\n",
    "            y_pred_train = dt_trained.predict(X_train)\n",
    "            regr_rslt.loc[train_test_round + 1, 'train'][label_col] = metric_fn(y_train, y_pred_train)\n",
    "\n",
    "            # Compare to a naive mean-value model:\n",
    "            y_pred_naive = np.ndarray(y_pred.shape)\n",
    "            y_pred_naive.fill(y_train.mean())\n",
    "            regr_rslt.loc[train_test_round + 1, 'naive'][label_col] = metric_fn(y_test, y_pred_naive)\n",
    "\n",
    "    for col in regr_rslt.columns:\n",
    "        summary.loc['avg(naive - test)'][col] = (regr_rslt[col].loc[:,'naive'] - regr_rslt[col].loc[:,'test']).mean()\n",
    "        summary.loc['avg(naive - train)'][col] = (regr_rslt[col].loc[:,'naive'] - regr_rslt[col].loc[:,'train']).mean()\n",
    "\n",
    "    return summary, regr_rslt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the 'first_7' rows are nans (for samples where n>20 but 7 days have not passed)\n",
    "\n",
    "Some of the Province_State are nans (Not all countries have provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins_confirmed = pd.read_pickle(PICKLE_PATH)\n",
    "nan_countries = []\n",
    "nan_first_7 = []\n",
    "for column in hopkins_confirmed.columns:\n",
    "    any_nan = hopkins_confirmed[column].loc[:, 'data'].isna().any()\n",
    "    nulls = hopkins_confirmed[column].loc[:, 'data'].isna().tolist()\n",
    "    if any_nan:\n",
    "        size = len([nul for nul in nulls if nul])\n",
    "        print('{0}: {1}, {2}'.format(column, any_nan, size))\n",
    "        for i in range(len(nulls)):\n",
    "            if column == 'Country_Region':\n",
    "                nc = hopkins_confirmed['Country_Region'].index[i][0]\n",
    "                nan_countries.append(nc)\n",
    "            if column == 'first_7':\n",
    "                nc = hopkins_confirmed['first_7'].index[i][0]\n",
    "                nan_first_7.append(nc)\n",
    "# hopkins_confirmed.drop(nan_first_7, level=0, inplace=True) # This was removed because it was buggy. the dropna is better and robust\n",
    "hopkins_confirmed['Province_State'] = hopkins_confirmed['Province_State'].fillna('')\n",
    "hopkins_confirmed.dropna(inplace=True)\n",
    "# Normalize first_7\n",
    "hopkins_confirmed['first_7'] = ((hopkins_confirmed['first_7'] + 1) ** (1/7) - 1)\n",
    "hopkins_confirmed.insert(4, 'tmp**2', np.nan)\n",
    "hopkins_confirmed.insert(4, 'tmp*rh', np.nan)\n",
    "hopkins_confirmed.insert(4, 'urb**2', np.nan)\n",
    "hopkins_confirmed.insert(4, 'tpc*max_cases', np.nan)\n",
    "\n",
    "hopkins_confirmed['tmp**2'] = hopkins_confirmed['avg_interval_tmp'] ** 2\n",
    "hopkins_confirmed['tmp*rh'] = hopkins_confirmed['avg_interval_tmp'] * hopkins_confirmed['avg_interval_RH']\n",
    "hopkins_confirmed['urb**2'] = hopkins_confirmed['Urbanization'] ** 2\n",
    "hopkins_confirmed['tpc*max_cases'] = hopkins_confirmed['Tests \\ Pop'] * hopkins_confirmed['Max_Cases']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>tpc*max_cases</th>\n",
       "      <th>urb**2</th>\n",
       "      <th>tmp*rh</th>\n",
       "      <th>tmp**2</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>State Population</th>\n",
       "      <th>Total Tests</th>\n",
       "      <th>Tests \\ Pop</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.00000</td>\n",
       "      <td>1.063000e+03</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52010.850986</td>\n",
       "      <td>74.345655</td>\n",
       "      <td>4.049610</td>\n",
       "      <td>5741.041760</td>\n",
       "      <td>889.387968</td>\n",
       "      <td>216.821170</td>\n",
       "      <td>37.55842</td>\n",
       "      <td>8.420330e+06</td>\n",
       "      <td>53037.816557</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>...</td>\n",
       "      <td>801.333020</td>\n",
       "      <td>877.954845</td>\n",
       "      <td>973.146754</td>\n",
       "      <td>1065.435560</td>\n",
       "      <td>1168.716839</td>\n",
       "      <td>1275.482596</td>\n",
       "      <td>1402.503293</td>\n",
       "      <td>1498.430856</td>\n",
       "      <td>1593.976482</td>\n",
       "      <td>1697.771402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21134.743739</td>\n",
       "      <td>14.627599</td>\n",
       "      <td>44.223118</td>\n",
       "      <td>2007.524040</td>\n",
       "      <td>528.155304</td>\n",
       "      <td>214.447040</td>\n",
       "      <td>4.25356</td>\n",
       "      <td>8.973202e+06</td>\n",
       "      <td>69192.186907</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>...</td>\n",
       "      <td>6814.353811</td>\n",
       "      <td>7483.586652</td>\n",
       "      <td>8312.659775</td>\n",
       "      <td>9136.641046</td>\n",
       "      <td>10074.017100</td>\n",
       "      <td>11074.739093</td>\n",
       "      <td>12233.869566</td>\n",
       "      <td>13114.647699</td>\n",
       "      <td>14028.638112</td>\n",
       "      <td>14993.075916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>396.000000</td>\n",
       "      <td>14.338000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>205.578244</td>\n",
       "      <td>-791.065974</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>15.10000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46232.989620</td>\n",
       "      <td>66.300000</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>4395.690000</td>\n",
       "      <td>472.749874</td>\n",
       "      <td>48.062130</td>\n",
       "      <td>36.55000</td>\n",
       "      <td>1.934408e+06</td>\n",
       "      <td>11246.000000</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55172.000000</td>\n",
       "      <td>75.100000</td>\n",
       "      <td>0.256355</td>\n",
       "      <td>5640.010000</td>\n",
       "      <td>809.339645</td>\n",
       "      <td>143.700156</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>6.045680e+06</td>\n",
       "      <td>31090.000000</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>...</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61594.000000</td>\n",
       "      <td>86.200000</td>\n",
       "      <td>0.870187</td>\n",
       "      <td>7430.440000</td>\n",
       "      <td>1245.540278</td>\n",
       "      <td>321.092273</td>\n",
       "      <td>39.30000</td>\n",
       "      <td>1.061742e+07</td>\n",
       "      <td>74655.000000</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>...</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>203.500000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>265.500000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>308.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200277.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1343.831024</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2403.747846</td>\n",
       "      <td>1232.010000</td>\n",
       "      <td>53.10000</td>\n",
       "      <td>3.951222e+07</td>\n",
       "      <td>340058.000000</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>...</td>\n",
       "      <td>140909.000000</td>\n",
       "      <td>161837.000000</td>\n",
       "      <td>188172.000000</td>\n",
       "      <td>213372.000000</td>\n",
       "      <td>243616.000000</td>\n",
       "      <td>275586.000000</td>\n",
       "      <td>308850.000000</td>\n",
       "      <td>337072.000000</td>\n",
       "      <td>366667.000000</td>\n",
       "      <td>396223.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GDP  Urbanization  tpc*max_cases        urb**2       tmp*rh  \\\n",
       "count    1063.000000   1063.000000    1063.000000   1063.000000  1063.000000   \n",
       "mean    52010.850986     74.345655       4.049610   5741.041760   889.387968   \n",
       "std     21134.743739     14.627599      44.223118   2007.524040   528.155304   \n",
       "min       396.000000     14.338000       0.000000    205.578244  -791.065974   \n",
       "25%     46232.989620     66.300000       0.094008   4395.690000   472.749874   \n",
       "50%     55172.000000     75.100000       0.256355   5640.010000   809.339645   \n",
       "75%     61594.000000     86.200000       0.870187   7430.440000  1245.540278   \n",
       "max    200277.000000    100.000000    1343.831024  10000.000000  2403.747846   \n",
       "\n",
       "            tmp**2  Median Age  State Population    Total Tests  Tests \\ Pop  \\\n",
       "count  1063.000000  1063.00000      1.063000e+03    1063.000000  1063.000000   \n",
       "mean    216.821170    37.55842      8.420330e+06   53037.816557     0.005411   \n",
       "std     214.447040     4.25356      8.973202e+06   69192.186907     0.004496   \n",
       "min       0.000947    15.10000      0.000000e+00       0.000000     0.000000   \n",
       "25%      48.062130    36.55000      1.934408e+06   11246.000000     0.003057   \n",
       "50%     143.700156    38.50000      6.045680e+06   31090.000000     0.004467   \n",
       "75%     321.092273    39.30000      1.061742e+07   74655.000000     0.006904   \n",
       "max    1232.010000    53.10000      3.951222e+07  340058.000000     0.017481   \n",
       "\n",
       "       ...      3/29/2020      3/30/2020      3/31/2020       4/1/2020  \\\n",
       "count  ...    1063.000000    1063.000000    1063.000000    1063.000000   \n",
       "mean   ...     801.333020     877.954845     973.146754    1065.435560   \n",
       "std    ...    6814.353811    7483.586652    8312.659775    9136.641046   \n",
       "min    ...       0.000000       0.000000       2.000000       2.000000   \n",
       "25%    ...      11.000000      13.000000      16.000000      18.000000   \n",
       "50%    ...      28.000000      33.000000      38.000000      44.000000   \n",
       "75%    ...     118.000000     135.000000     152.000000     173.500000   \n",
       "max    ...  140909.000000  161837.000000  188172.000000  213372.000000   \n",
       "\n",
       "            4/2/2020       4/3/2020       4/4/2020       4/5/2020  \\\n",
       "count    1063.000000    1063.000000    1063.000000    1063.000000   \n",
       "mean     1168.716839    1275.482596    1402.503293    1498.430856   \n",
       "std     10074.017100   11074.739093   12233.869566   13114.647699   \n",
       "min         4.000000       4.000000       0.000000       0.000000   \n",
       "25%        21.000000      23.500000      27.000000      30.500000   \n",
       "50%        51.000000      58.000000      66.000000      73.000000   \n",
       "75%       203.500000     222.000000     251.000000     265.500000   \n",
       "max    243616.000000  275586.000000  308850.000000  337072.000000   \n",
       "\n",
       "            4/6/2020       4/7/2020  \n",
       "count    1063.000000    1063.000000  \n",
       "mean     1593.976482    1697.771402  \n",
       "std     14028.638112   14993.075916  \n",
       "min         0.000000      17.000000  \n",
       "25%        33.000000      37.000000  \n",
       "50%        79.000000      88.000000  \n",
       "75%       286.000000     308.500000  \n",
       "max    366667.000000  396223.000000  \n",
       "\n",
       "[8 rows x 101 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopkins_confirmed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>tpc*max_cases</th>\n",
       "      <th>urb**2</th>\n",
       "      <th>tmp*rh</th>\n",
       "      <th>tmp**2</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Democracy</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinate</th>\n",
       "      <th>information</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-41.4545, 145.9707)</th>\n",
       "      <th>data</th>\n",
       "      <td>Tasmania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>57373.68668</td>\n",
       "      <td>86.012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7398.064144</td>\n",
       "      <td>1011.709440</td>\n",
       "      <td>176.464656</td>\n",
       "      <td>37.900002</td>\n",
       "      <td>9.09</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-40.9006, 174.886)</th>\n",
       "      <th>data</th>\n",
       "      <td></td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>41945.33167</td>\n",
       "      <td>86.538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7488.825444</td>\n",
       "      <td>1191.210938</td>\n",
       "      <td>220.336914</td>\n",
       "      <td>37.900002</td>\n",
       "      <td>9.26</td>\n",
       "      <td>...</td>\n",
       "      <td>514.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>1160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-38.4161, -63.6167)</th>\n",
       "      <th>data</th>\n",
       "      <td></td>\n",
       "      <td>Argentina</td>\n",
       "      <td>11683.94962</td>\n",
       "      <td>91.870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8440.096900</td>\n",
       "      <td>950.908587</td>\n",
       "      <td>341.277008</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>7.02</td>\n",
       "      <td>...</td>\n",
       "      <td>745.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>1628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-37.8136, 144.9631)</th>\n",
       "      <th>data</th>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>57373.68668</td>\n",
       "      <td>86.012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7398.064144</td>\n",
       "      <td>1172.411570</td>\n",
       "      <td>290.237686</td>\n",
       "      <td>37.900002</td>\n",
       "      <td>9.09</td>\n",
       "      <td>...</td>\n",
       "      <td>769.0</td>\n",
       "      <td>821.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>1191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-35.6751, -71.543)</th>\n",
       "      <th>data</th>\n",
       "      <td></td>\n",
       "      <td>Chile</td>\n",
       "      <td>15923.35874</td>\n",
       "      <td>87.564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7667.454096</td>\n",
       "      <td>1081.266667</td>\n",
       "      <td>273.902500</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>8.08</td>\n",
       "      <td>...</td>\n",
       "      <td>2139.0</td>\n",
       "      <td>2449.0</td>\n",
       "      <td>2738.0</td>\n",
       "      <td>3031.0</td>\n",
       "      <td>3404.0</td>\n",
       "      <td>3737.0</td>\n",
       "      <td>4161.0</td>\n",
       "      <td>4471.0</td>\n",
       "      <td>4815.0</td>\n",
       "      <td>5116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(61.8926, -6.9118)</th>\n",
       "      <th>data</th>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>61350.34791</td>\n",
       "      <td>87.874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7721.839876</td>\n",
       "      <td>382.921330</td>\n",
       "      <td>25.210970</td>\n",
       "      <td>42.299999</td>\n",
       "      <td>9.22</td>\n",
       "      <td>...</td>\n",
       "      <td>159.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(63.0, 16.0)</th>\n",
       "      <th>data</th>\n",
       "      <td></td>\n",
       "      <td>Sweden</td>\n",
       "      <td>54608.36025</td>\n",
       "      <td>87.431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7644.179761</td>\n",
       "      <td>-28.533608</td>\n",
       "      <td>0.165981</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>9.39</td>\n",
       "      <td>...</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>4028.0</td>\n",
       "      <td>4435.0</td>\n",
       "      <td>4947.0</td>\n",
       "      <td>5568.0</td>\n",
       "      <td>6131.0</td>\n",
       "      <td>6443.0</td>\n",
       "      <td>6830.0</td>\n",
       "      <td>7206.0</td>\n",
       "      <td>7693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(64.0, 26.0)</th>\n",
       "      <th>data</th>\n",
       "      <td></td>\n",
       "      <td>Finland</td>\n",
       "      <td>50152.34014</td>\n",
       "      <td>85.382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7290.085924</td>\n",
       "      <td>-191.987520</td>\n",
       "      <td>7.420176</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>9.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>2308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(64.80726247, -146.5692662)</th>\n",
       "      <th>data</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>US</td>\n",
       "      <td>73205.00000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>0.614241</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>-344.814815</td>\n",
       "      <td>29.641975</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>7.96</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(64.9631, -19.0208)</th>\n",
       "      <th>data</th>\n",
       "      <td></td>\n",
       "      <td>Iceland</td>\n",
       "      <td>73191.11632</td>\n",
       "      <td>93.813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8800.878969</td>\n",
       "      <td>-51.726749</td>\n",
       "      <td>0.505679</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>9.58</td>\n",
       "      <td>...</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>1586.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Province_State Country_Region  \\\n",
       "coordinate                  information                                 \n",
       "(-41.4545, 145.9707)        data              Tasmania      Australia   \n",
       "(-40.9006, 174.886)         data                          New Zealand   \n",
       "(-38.4161, -63.6167)        data                            Argentina   \n",
       "(-37.8136, 144.9631)        data              Victoria      Australia   \n",
       "(-35.6751, -71.543)         data                                Chile   \n",
       "...                                                ...            ...   \n",
       "(61.8926, -6.9118)          data         Faroe Islands        Denmark   \n",
       "(63.0, 16.0)                data                               Sweden   \n",
       "(64.0, 26.0)                data                              Finland   \n",
       "(64.80726247, -146.5692662) data                Alaska             US   \n",
       "(64.9631, -19.0208)         data                              Iceland   \n",
       "\n",
       "                                                 GDP  Urbanization  \\\n",
       "coordinate                  information                              \n",
       "(-41.4545, 145.9707)        data         57373.68668        86.012   \n",
       "(-40.9006, 174.886)         data         41945.33167        86.538   \n",
       "(-38.4161, -63.6167)        data         11683.94962        91.870   \n",
       "(-37.8136, 144.9631)        data         57373.68668        86.012   \n",
       "(-35.6751, -71.543)         data         15923.35874        87.564   \n",
       "...                                              ...           ...   \n",
       "(61.8926, -6.9118)          data         61350.34791        87.874   \n",
       "(63.0, 16.0)                data         54608.36025        87.431   \n",
       "(64.0, 26.0)                data         50152.34014        85.382   \n",
       "(64.80726247, -146.5692662) data         73205.00000        66.000   \n",
       "(64.9631, -19.0208)         data         73191.11632        93.813   \n",
       "\n",
       "                                         tpc*max_cases       urb**2  \\\n",
       "coordinate                  information                               \n",
       "(-41.4545, 145.9707)        data              0.000000  7398.064144   \n",
       "(-40.9006, 174.886)         data              0.000000  7488.825444   \n",
       "(-38.4161, -63.6167)        data              0.000000  8440.096900   \n",
       "(-37.8136, 144.9631)        data              0.000000  7398.064144   \n",
       "(-35.6751, -71.543)         data              0.000000  7667.454096   \n",
       "...                                                ...          ...   \n",
       "(61.8926, -6.9118)          data              0.000000  7721.839876   \n",
       "(63.0, 16.0)                data              0.000000  7644.179761   \n",
       "(64.0, 26.0)                data              0.000000  7290.085924   \n",
       "(64.80726247, -146.5692662) data              0.614241  4356.000000   \n",
       "(64.9631, -19.0208)         data              0.000000  8800.878969   \n",
       "\n",
       "                                              tmp*rh      tmp**2  Median Age  \\\n",
       "coordinate                  information                                        \n",
       "(-41.4545, 145.9707)        data         1011.709440  176.464656   37.900002   \n",
       "(-40.9006, 174.886)         data         1191.210938  220.336914   37.900002   \n",
       "(-38.4161, -63.6167)        data          950.908587  341.277008   31.900000   \n",
       "(-37.8136, 144.9631)        data         1172.411570  290.237686   37.900002   \n",
       "(-35.6751, -71.543)         data         1081.266667  273.902500   35.400002   \n",
       "...                                              ...         ...         ...   \n",
       "(61.8926, -6.9118)          data          382.921330   25.210970   42.299999   \n",
       "(63.0, 16.0)                data          -28.533608    0.165981   41.000000   \n",
       "(64.0, 26.0)                data         -191.987520    7.420176   42.799999   \n",
       "(64.80726247, -146.5692662) data         -344.814815   29.641975   34.000000   \n",
       "(64.9631, -19.0208)         data          -51.726749    0.505679   37.299999   \n",
       "\n",
       "                                        Democracy  ...  3/29/2020  3/30/2020  \\\n",
       "coordinate                  information            ...                         \n",
       "(-41.4545, 145.9707)        data             9.09  ...       66.0       66.0   \n",
       "(-40.9006, 174.886)         data             9.26  ...      514.0      589.0   \n",
       "(-38.4161, -63.6167)        data             7.02  ...      745.0      820.0   \n",
       "(-37.8136, 144.9631)        data             9.09  ...      769.0      821.0   \n",
       "(-35.6751, -71.543)         data             8.08  ...     2139.0     2449.0   \n",
       "...                                           ...  ...        ...        ...   \n",
       "(61.8926, -6.9118)          data             9.22  ...      159.0      168.0   \n",
       "(63.0, 16.0)                data             9.39  ...     3700.0     4028.0   \n",
       "(64.0, 26.0)                data             9.25  ...     1240.0     1352.0   \n",
       "(64.80726247, -146.5692662) data             7.96  ...       23.0       28.0   \n",
       "(64.9631, -19.0208)         data             9.58  ...     1020.0     1086.0   \n",
       "\n",
       "                                         3/31/2020  4/1/2020  4/2/2020  \\\n",
       "coordinate                  information                                  \n",
       "(-41.4545, 145.9707)        data              69.0      69.0      72.0   \n",
       "(-40.9006, 174.886)         data             647.0     708.0     797.0   \n",
       "(-38.4161, -63.6167)        data            1054.0    1054.0    1133.0   \n",
       "(-37.8136, 144.9631)        data             917.0     968.0    1036.0   \n",
       "(-35.6751, -71.543)         data            2738.0    3031.0    3404.0   \n",
       "...                                            ...       ...       ...   \n",
       "(61.8926, -6.9118)          data             169.0     173.0     177.0   \n",
       "(63.0, 16.0)                data            4435.0    4947.0    5568.0   \n",
       "(64.0, 26.0)                data            1418.0    1446.0    1518.0   \n",
       "(64.80726247, -146.5692662) data              30.0      35.0      40.0   \n",
       "(64.9631, -19.0208)         data            1135.0    1220.0    1319.0   \n",
       "\n",
       "                                         4/3/2020  4/4/2020  4/5/2020  \\\n",
       "coordinate                  information                                 \n",
       "(-41.4545, 145.9707)        data             74.0      80.0      82.0   \n",
       "(-40.9006, 174.886)         data            868.0     950.0    1039.0   \n",
       "(-38.4161, -63.6167)        data           1265.0    1451.0    1451.0   \n",
       "(-37.8136, 144.9631)        data           1085.0    1115.0    1135.0   \n",
       "(-35.6751, -71.543)         data           3737.0    4161.0    4471.0   \n",
       "...                                           ...       ...       ...   \n",
       "(61.8926, -6.9118)          data            179.0     181.0     181.0   \n",
       "(63.0, 16.0)                data           6131.0    6443.0    6830.0   \n",
       "(64.0, 26.0)                data           1615.0    1882.0    1927.0   \n",
       "(64.80726247, -146.5692662) data             42.0      46.0      53.0   \n",
       "(64.9631, -19.0208)         data           1364.0    1417.0    1486.0   \n",
       "\n",
       "                                         4/6/2020 4/7/2020  \n",
       "coordinate                  information                     \n",
       "(-41.4545, 145.9707)        data             86.0     89.0  \n",
       "(-40.9006, 174.886)         data           1106.0   1160.0  \n",
       "(-38.4161, -63.6167)        data           1554.0   1628.0  \n",
       "(-37.8136, 144.9631)        data           1158.0   1191.0  \n",
       "(-35.6751, -71.543)         data           4815.0   5116.0  \n",
       "...                                           ...      ...  \n",
       "(61.8926, -6.9118)          data            183.0    184.0  \n",
       "(63.0, 16.0)                data           7206.0   7693.0  \n",
       "(64.0, 26.0)                data           2176.0   2308.0  \n",
       "(64.80726247, -146.5692662) data             53.0     65.0  \n",
       "(64.9631, -19.0208)         data           1562.0   1586.0  \n",
       "\n",
       "[1063 rows x 107 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopkins_confirmed#.loc[euro_coords, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "regression - US\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_7</th>\n",
       "      <th>GF_Q1</th>\n",
       "      <th>GF_Q2</th>\n",
       "      <th>GF_Q3</th>\n",
       "      <th>EXP_GF_Q1</th>\n",
       "      <th>EXP_GF_Q2</th>\n",
       "      <th>EXP_GF_Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg(naive - test)</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg(naive - train)</th>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     first_7     GF_Q1     GF_Q2     GF_Q3  EXP_GF_Q1  \\\n",
       "avg(naive - test)   0.000102  0.000049  0.000150 -0.000079  -0.000477   \n",
       "avg(naive - train)  0.000209  0.000209  0.000217  0.000458   0.000204   \n",
       "\n",
       "                    EXP_GF_Q2  EXP_GF_Q3  \n",
       "avg(naive - test)   -0.000245   0.000236  \n",
       "avg(naive - train)   0.000242   0.000637  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree - US\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_7</th>\n",
       "      <th>GF_Q1</th>\n",
       "      <th>GF_Q2</th>\n",
       "      <th>GF_Q3</th>\n",
       "      <th>EXP_GF_Q1</th>\n",
       "      <th>EXP_GF_Q2</th>\n",
       "      <th>EXP_GF_Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg(naive - test)</th>\n",
       "      <td>-0.000317</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.001207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg(naive - train)</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.002479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     first_7     GF_Q1     GF_Q2     GF_Q3  EXP_GF_Q1  \\\n",
       "avg(naive - test)  -0.000317  0.000287 -0.000072 -0.000190  -0.000546   \n",
       "avg(naive - train)  0.000967  0.000728  0.000950  0.001667   0.000672   \n",
       "\n",
       "                    EXP_GF_Q2  EXP_GF_Q3  \n",
       "avg(naive - test)   -0.000132  -0.001207  \n",
       "avg(naive - train)   0.001291   0.002479  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "regression - Europe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_7</th>\n",
       "      <th>GF_Q1</th>\n",
       "      <th>GF_Q2</th>\n",
       "      <th>GF_Q3</th>\n",
       "      <th>EXP_GF_Q1</th>\n",
       "      <th>EXP_GF_Q2</th>\n",
       "      <th>EXP_GF_Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg(naive - test)</th>\n",
       "      <td>-0.000696</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001499</td>\n",
       "      <td>-0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg(naive - train)</th>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.001647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     first_7     GF_Q1     GF_Q2     GF_Q3  EXP_GF_Q1  \\\n",
       "avg(naive - test)  -0.000696 -0.000208 -0.000628 -0.000808        NaN   \n",
       "avg(naive - train)  0.001253  0.000249  0.000293  0.000664        NaN   \n",
       "\n",
       "                    EXP_GF_Q2  EXP_GF_Q3  \n",
       "avg(naive - test)   -0.001499  -0.002280  \n",
       "avg(naive - train)   0.000859   0.001647  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree - Europe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_7</th>\n",
       "      <th>GF_Q1</th>\n",
       "      <th>GF_Q2</th>\n",
       "      <th>GF_Q3</th>\n",
       "      <th>EXP_GF_Q1</th>\n",
       "      <th>EXP_GF_Q2</th>\n",
       "      <th>EXP_GF_Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg(naive - test)</th>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-0.001871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002754</td>\n",
       "      <td>-0.006962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg(naive - train)</th>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.003848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     first_7     GF_Q1     GF_Q2     GF_Q3  EXP_GF_Q1  \\\n",
       "avg(naive - test)  -0.000752 -0.000180 -0.000376 -0.001871        NaN   \n",
       "avg(naive - train)  0.001867  0.000404  0.000740  0.001516        NaN   \n",
       "\n",
       "                    EXP_GF_Q2  EXP_GF_Q3  \n",
       "avg(naive - test)   -0.002754  -0.006962  \n",
       "avg(naive - train)   0.001713   0.003848  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "regression - global with thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_7</th>\n",
       "      <th>GF_Q1</th>\n",
       "      <th>GF_Q2</th>\n",
       "      <th>GF_Q3</th>\n",
       "      <th>EXP_GF_Q1</th>\n",
       "      <th>EXP_GF_Q2</th>\n",
       "      <th>EXP_GF_Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg(naive - test)</th>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>-0.001210</td>\n",
       "      <td>-0.125721</td>\n",
       "      <td>-0.001385</td>\n",
       "      <td>-0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg(naive - train)</th>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.001366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     first_7     GF_Q1     GF_Q2     GF_Q3  EXP_GF_Q1  \\\n",
       "avg(naive - test)  -0.000109 -0.000135 -0.000848 -0.001210  -0.125721   \n",
       "avg(naive - train)  0.000507  0.000334  0.000262  0.000798   0.000286   \n",
       "\n",
       "                    EXP_GF_Q2  EXP_GF_Q3  \n",
       "avg(naive - test)   -0.001385  -0.001417  \n",
       "avg(naive - train)   0.000720   0.001366  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree - global with thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_7</th>\n",
       "      <th>GF_Q1</th>\n",
       "      <th>GF_Q2</th>\n",
       "      <th>GF_Q3</th>\n",
       "      <th>EXP_GF_Q1</th>\n",
       "      <th>EXP_GF_Q2</th>\n",
       "      <th>EXP_GF_Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg(naive - test)</th>\n",
       "      <td>-0.002178</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.002121</td>\n",
       "      <td>-0.008416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg(naive - train)</th>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.006953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     first_7     GF_Q1     GF_Q2     GF_Q3  EXP_GF_Q1  \\\n",
       "avg(naive - test)  -0.002178 -0.000349 -0.000594 -0.001042  -0.000816   \n",
       "avg(naive - train)  0.002257  0.000978  0.001253  0.002103   0.000723   \n",
       "\n",
       "                    EXP_GF_Q2  EXP_GF_Q3  \n",
       "avg(naive - test)   -0.002121  -0.008416  \n",
       "avg(naive - train)   0.002494   0.006953  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "regression - global\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_7</th>\n",
       "      <th>GF_Q1</th>\n",
       "      <th>GF_Q2</th>\n",
       "      <th>GF_Q3</th>\n",
       "      <th>EXP_GF_Q1</th>\n",
       "      <th>EXP_GF_Q2</th>\n",
       "      <th>EXP_GF_Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg(naive - test)</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>-0.000188</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg(naive - train)</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     first_7     GF_Q1     GF_Q2     GF_Q3  EXP_GF_Q1  \\\n",
       "avg(naive - test)   0.000021  0.000028  0.000107  0.000537  -0.000188   \n",
       "avg(naive - train)  0.000102  0.000104  0.000171  0.000691   0.000194   \n",
       "\n",
       "                    EXP_GF_Q2  EXP_GF_Q3  \n",
       "avg(naive - test)    0.000089   0.000468  \n",
       "avg(naive - train)   0.000200   0.000801  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree - global\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_7</th>\n",
       "      <th>GF_Q1</th>\n",
       "      <th>GF_Q2</th>\n",
       "      <th>GF_Q3</th>\n",
       "      <th>EXP_GF_Q1</th>\n",
       "      <th>EXP_GF_Q2</th>\n",
       "      <th>EXP_GF_Q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg(naive - test)</th>\n",
       "      <td>-0.00051</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg(naive - train)</th>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.002528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    first_7     GF_Q1     GF_Q2     GF_Q3  EXP_GF_Q1  \\\n",
       "avg(naive - test)  -0.00051  0.000032  0.000098  0.000049  -0.000566   \n",
       "avg(naive - train)  0.00077  0.000513  0.000738  0.002082   0.000702   \n",
       "\n",
       "                    EXP_GF_Q2  EXP_GF_Q3  \n",
       "avg(naive - test)   -0.000051  -0.000107  \n",
       "avg(naive - train)   0.001014   0.002528  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_feature_cols = ['GDP', 'Urbanization', 'avg_interval_tmp', 'avg_interval_RH',\\\n",
    "               'tmp**2', 'tmp*rh', 'urb**2', 'tpc*max_cases', 'Democracy', 'Median Age', 'Tests \\ Pop']\n",
    "\n",
    "global_feature_cols = ['GDP', 'Urbanization', 'avg_interval_tmp', 'avg_interval_RH',\\\n",
    "               'tmp**2', 'tmp*rh', 'urb**2', 'Democracy', 'Median Age']\n",
    "\n",
    "label_cols = ['first_7', 'GF_Q1', 'GF_Q2', 'GF_Q3', 'EXP_GF_Q1', 'EXP_GF_Q2', 'EXP_GF_Q3']\n",
    "coords = list(set(hopkins_confirmed.index.get_level_values(0)))\n",
    "euro_coords = [coord for coord in coords if (coord[0] > 36.7 and coord[1] > -16 and coord[1] < 25)]\n",
    "thrsh_data = hopkins_confirmed[hopkins_confirmed['GDP'] >= 40000]\\\n",
    "                        [hopkins_confirmed['Urbanization'] >= 88].copy()\n",
    "\n",
    "\n",
    "us_regr_sum, us_regr_full = regression(hopkins_confirmed[hopkins_confirmed['Country_Region'] =='US'].copy(),\\\n",
    "                                       us_feature_cols, label_cols)\n",
    "\n",
    "us_dt_sum, us_dt_full = dt(hopkins_confirmed[hopkins_confirmed['Country_Region'] =='US'].copy(),\\\n",
    "                           us_feature_cols, label_cols)\n",
    "\n",
    "euro_regr_sum, euro_regr_full = regression(hopkins_confirmed.loc[euro_coords, :, :].copy(),\\\n",
    "                                          global_feature_cols, label_cols)\n",
    "\n",
    "euro_dt_sum, euro_dt_full = dt(hopkins_confirmed.loc[euro_coords, :, :].copy(),\\\n",
    "                              global_feature_cols, label_cols)\n",
    "\n",
    "global_regr_sum, global_regr_full = regression(hopkins_confirmed, global_feature_cols, label_cols)\n",
    "\n",
    "global_dt_sum, global_dt_full = dt(hopkins_confirmed, global_feature_cols, label_cols)\n",
    "\n",
    "thrsh_regr_sum, thrsh_regr_full = regression(thrsh_data, global_feature_cols, label_cols)\n",
    "\n",
    "thrsh_dt_sum, thrsh_dt_full = dt(thrsh_data, global_feature_cols, label_cols)\n",
    "\n",
    "print('\\nregression - US')\n",
    "us_regr_sum\n",
    "print('Decision tree - US')\n",
    "us_dt_sum\n",
    "\n",
    "print('\\nregression - Europe')\n",
    "euro_regr_sum\n",
    "print('Decision tree - Europe')\n",
    "euro_dt_sum\n",
    "\n",
    "print('\\nregression - global with thresholds')\n",
    "thrsh_regr_sum\n",
    "print('Decision tree - global with thresholds')\n",
    "thrsh_dt_sum\n",
    "\n",
    "print('\\nregression - global')\n",
    "global_regr_sum\n",
    "print('Decision tree - global')\n",
    "global_dt_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Median Age', 'Democracy', 'State Population', 'Total Tests',\n",
       "       'Tests \\ Pop', 'avg_m_tmp', 'avg_m_RH', 'avg_m_precip', 'avg_m_wind',\n",
       "       'Max_Cases', 'first_7', 'last relevant date', 'Max_Date', '5%_Date',\n",
       "       'avg_interval_tmp', 'avg_interval_RH', 'GF_Q1', 'GF_Q2', 'GF_Q3',\n",
       "       'EXP_GF_Q1', 'EXP_GF_Q2', 'EXP_GF_Q3', '1/22/2020', '1/23/2020',\n",
       "       '1/24/2020', '1/25/2020', '1/26/2020', '1/27/2020', '1/28/2020',\n",
       "       '1/29/2020', '1/30/2020', '1/31/2020', '2/1/2020', '2/2/2020',\n",
       "       '2/3/2020', '2/4/2020', '2/5/2020', '2/6/2020', '2/7/2020', '2/8/2020',\n",
       "       '2/9/2020', '2/10/2020', '2/11/2020', '2/12/2020', '2/13/2020',\n",
       "       '2/14/2020', '2/15/2020', '2/16/2020', '2/17/2020', '2/18/2020',\n",
       "       '2/19/2020', '2/20/2020', '2/21/2020', '2/22/2020', '2/23/2020',\n",
       "       '2/24/2020', '2/25/2020', '2/26/2020', '2/27/2020', '2/28/2020',\n",
       "       '2/29/2020', '3/1/2020', '3/2/2020', '3/3/2020', '3/4/2020', '3/5/2020',\n",
       "       '3/6/2020', '3/7/2020', '3/8/2020', '3/9/2020', '3/10/2020',\n",
       "       '3/11/2020', '3/12/2020', '3/13/2020', '3/14/2020', '3/15/2020',\n",
       "       '3/16/2020', '3/17/2020', '3/18/2020', '3/19/2020', '3/20/2020',\n",
       "       '3/21/2020', '3/22/2020', '3/23/2020', '3/24/2020', '3/25/2020',\n",
       "       '3/26/2020', '3/27/2020', '3/28/2020', '3/29/2020', '3/30/2020',\n",
       "       '3/31/2020', '4/1/2020', '4/2/2020', '4/3/2020', '4/4/2020', '4/5/2020',\n",
       "       '4/6/2020', '4/7/2020'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopkins_confirmed.columns[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = dt(thrsh_data, global_feature_cols, label_cols)\n",
    "_ = dt(hopkins_confirmed[hopkins_confirmed['Country_Region'] =='US'].copy(), us_feature_cols, label_cols)\n",
    "!dot -Tpng ../products/decision_tree/decision_tree_GF_Q1_run4.dot -o tree.png && open tree.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
