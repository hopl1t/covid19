{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from urllib.error import URLError\n",
    "from functools import wraps\n",
    "from keys import client_id, client_secret, app_id\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEATH_PATH = '../augmented_datasets/pickles/hopkins_death_withgr_augmented0605.pkl'\n",
    "CONF_PATH = '../augmented_datasets/pickles/hopkins_conf_withgr_augmented0605_withsocietal.pkl'\n",
    "COLS = ['GDP', 'Urbanization', 'Median Age',\\\n",
    "        'Democracy', 'Gini Index', 'State Population',\\\n",
    "        'Total Tests', 'Tests \\\\ Pop', 'avg_mobility', 'Tests per 1M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_index(df, row_name, gap=5):\n",
    "    \"\"\"\n",
    "    Adds a row on level 1 of a df\n",
    "    \"\"\"\n",
    "    idx = df.index\n",
    "    previous_coor = (0,0)\n",
    "    i = gap\n",
    "    for coor, data in df.iterrows():\n",
    "        coor = coor[0]\n",
    "        if coor != previous_coor:\n",
    "            idx = idx.insert(i, (coor, row_name))\n",
    "            i += (gap + 1)\n",
    "            previous_coor = coor\n",
    "    return df.copy().reindex(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins_death = pd.read_pickle(DEATH_PATH)\n",
    "hopkins_conf = pd.read_pickle(CONF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins_death = add_index(hopkins_death, 'd_mob_change')\n",
    "hopkins_conf.insert(11, 'avg_mobility', np.nan)\n",
    "for col in COLS[::-1]:\n",
    "    hopkins_death.insert(2, col, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Merge with data from confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1837"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1254"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_indexs = []\n",
    "death_indexs = []\n",
    "for row in hopkins_conf.iterrows():\n",
    "    conf_indexs.append(row[0][0])\n",
    "for row in hopkins_death.iterrows():\n",
    "    death_indexs.append(row[0][0])\n",
    "\n",
    "len(set(conf_indexs))\n",
    "len(set(death_indexs))\n",
    "\n",
    "conf_ind =  set(conf_indexs)\n",
    "death_ind = set(death_indexs)\n",
    "to_drop = [ind for ind in death_ind if ind not in conf_ind]\n",
    "len(to_drop)\n",
    "# hopkins_death.drop(index=to_drop, level=0, inplace=True)\n",
    "\n",
    "coords = []\n",
    "for row in hopkins_death.iterrows():\n",
    "    coords.append(row[0][0])\n",
    "coords = list(set(coords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins_death.insert(12, 'avg_interval_tmp', np.nan)\n",
    "hopkins_death.insert(12, 'avg_interval_RH', np.nan)\n",
    "hopkins_conf.insert(12, 'avg_interval_tmp', np.nan)\n",
    "hopkins_conf.insert(12, 'avg_interval_RH', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = hopkins_conf.columns.tolist()[34:]\n",
    "hopkins_conf['Tests per 1M'] = hopkins_conf['Tests per 1M'].iloc[:].str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins_death = pd.read_pickle('../augmented_datasets/pickles/death_data_gr_fix_0605.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### this is a patch to get a new df with gf for death cases > 2 rather then 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coord in coords:\n",
    "    for col in COLS:\n",
    "        hopkins_death.loc[coord, col]['data'] = hopkins_conf.loc[coord, col]['data']\n",
    "    for day in days:\n",
    "        hopkins_death.loc[coord, day]['d_mob_change'] = hopkins_conf.loc[coord, day]['d_mob_change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculate avg interval temp and mobility for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = set(hopkins_conf.index.get_level_values(0).tolist())\n",
    "for coord in coords:\n",
    "    try:\n",
    "        last_rel_date = hopkins_conf.loc[coord]['last relevant date']['data']\n",
    "        five_prcnt_date = hopkins_conf.loc[coord]['5%_Date']['data']\n",
    "\n",
    "        five_prct_column = hopkins_conf.columns.get_loc(five_prcnt_date)\n",
    "        last_rel_column = hopkins_conf.columns.get_loc(last_rel_date)\n",
    "        interval = hopkins_conf[hopkins_conf.columns[five_prct_column:last_rel_column]]\n",
    "\n",
    "        hopkins_conf.loc[coord, 'avg_interval_tmp']['data'] = interval.loc[coord].loc['avg_d_tmp'].mean()\n",
    "        hopkins_conf.loc[coord, 'avg_interval_RH']['data'] = interval.loc[coord].loc['avg_d_RH'].mean()\n",
    "        hopkins_conf.loc[coord, 'avg_mobility']['data'] = interval.loc[coord].loc['d_mob_change'].mean()\n",
    "    except KeyError as e:\n",
    "#         raise e\n",
    "        print('key error, {0}'.format(coord))\n",
    "\n",
    "coords = set(hopkins_death.index.get_level_values(0).tolist())\n",
    "for coord in coords:\n",
    "    try:\n",
    "        last_rel_date = hopkins_death.loc[coord]['last relevant date']['data']\n",
    "        five_prcnt_date = hopkins_death.loc[coord]['5%_Date']['data']\n",
    "\n",
    "        five_prct_column = hopkins_death.columns.get_loc(five_prcnt_date)\n",
    "        last_rel_column = hopkins_death.columns.get_loc(last_rel_date)\n",
    "        interval = hopkins_death[hopkins_death.columns[five_prct_column:last_rel_column]]\n",
    "\n",
    "        hopkins_death.loc[coord, 'avg_interval_tmp']['data'] = interval.loc[coord].loc['avg_d_tmp'].mean()\n",
    "        hopkins_death.loc[coord, 'avg_interval_RH']['data'] = interval.loc[coord].loc['avg_d_RH'].mean()\n",
    "        hopkins_death.loc[coord, 'avg_mobility']['data'] = interval.loc[coord].loc['d_mob_change'].mean()\n",
    "    except KeyError as e:\n",
    "        raise e\n",
    "#         print('key error, {0}'.format(coord))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### fill place with no mobility data with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amount of lications with no google movment data\n",
    "len([loc for loc in np.isnan(hopkins_conf['avg_mobility'][::7]) if loc])\n",
    "hopkins_conf['avg_mobility'][::7].fillna(hopkins_conf['avg_mobility'][::7].mean(), inplace=True)\n",
    "hopkins_death['avg_mobility'][::7].fillna(hopkins_death['avg_mobility'][::7].mean(), inplace=True)\n",
    "len([loc for loc in np.isnan(hopkins_conf['avg_mobility'][::7]) if loc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### prepare narrow dataset (no daily data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Save augmented data\n",
    "1. Multi index does not save well in csv, so we also save it as a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = '../augmented_datasets/pickles/hopkins_death_augmented0605.pkl' \n",
    "hopkins_death.to_pickle(pickle_path)\n",
    "'../augmented_datasets/pickles/hop'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
