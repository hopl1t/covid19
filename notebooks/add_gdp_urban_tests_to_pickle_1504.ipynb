{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add [GDP, Urbanization, Democracy Index, Median Age, Daily Tests] Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the following data:\n",
    "- GDP in billion USD per country (per US states and China provinces, with plans to add Australian, French, and Canadian provinces as well)\n",
    "- Urbanization as population percentage per country (per US states and China provinces, with plans to add Australian, French, and Canadian provinces as well)\n",
    "- Democracy Index per country\n",
    "- Median Age per country and per US state (with plans to add sub region data for other countries like above)\n",
    "- Number of Daily tests per US state (we don't believe we will get accurate data for this metric for other subregions)\n",
    "- We wanted to do Gini Index as well but didn't get to it\n",
    "\n",
    "\n",
    "Contact ShuliFinley@gmail.com for questions :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Import and load hopkins data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PICKLE_PATH = '../augmented_datasets/pickles/hopkins_conf_gf0904.pkl'\n",
    "# RESULT_PATH = '../augmented_datasets/pickles/hopkins_conf_gf0904_GDP_urban_tests.pkl'\n",
    "\n",
    "PICKLE_PATH = '../augmented_datasets/pickles/hopkins_conf_gf0904_GDP_urban_weather.pkl'\n",
    "RESULT_PATH = '../augmented_datasets/pickles/hopkins_conf_gf0904_GDP_urban_weather_dem_age_dtests_pop.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>avg_m_tmp</th>\n",
       "      <th>avg_m_RH</th>\n",
       "      <th>avg_m_precip</th>\n",
       "      <th>avg_m_wind</th>\n",
       "      <th>Max_Cases</th>\n",
       "      <th>first_7</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinate</th>\n",
       "      <th>information</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">(-41.4545, 145.9707)</th>\n",
       "      <th>data</th>\n",
       "      <td>Tasmania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>57373.68668</td>\n",
       "      <td>86.012</td>\n",
       "      <td>15.105195</td>\n",
       "      <td>70.402597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.087013</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_RH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_precip</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_tmp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_wind</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">(64.9631, -19.0208)</th>\n",
       "      <th>data</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>73191.11632</td>\n",
       "      <td>93.813</td>\n",
       "      <td>-1.909459</td>\n",
       "      <td>77.459459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.535135</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>1.588235</td>\n",
       "      <td>...</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>1586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_RH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_precip</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_tmp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_wind</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>31.3</td>\n",
       "      <td>31.4</td>\n",
       "      <td>25.9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>21.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>17.3</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5350 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Province_State Country_Region          GDP  \\\n",
       "coordinate           information                                               \n",
       "(-41.4545, 145.9707) data               Tasmania      Australia  57373.68668   \n",
       "                     avg_d_RH                NaN            NaN          NaN   \n",
       "                     avg_d_precip            NaN            NaN          NaN   \n",
       "                     avg_d_tmp               NaN            NaN          NaN   \n",
       "                     avg_d_wind              NaN            NaN          NaN   \n",
       "...                                          ...            ...          ...   \n",
       "(64.9631, -19.0208)  data                    NaN        Iceland  73191.11632   \n",
       "                     avg_d_RH                NaN            NaN          NaN   \n",
       "                     avg_d_precip            NaN            NaN          NaN   \n",
       "                     avg_d_tmp               NaN            NaN          NaN   \n",
       "                     avg_d_wind              NaN            NaN          NaN   \n",
       "\n",
       "                                   Urbanization  avg_m_tmp   avg_m_RH  \\\n",
       "coordinate           information                                        \n",
       "(-41.4545, 145.9707) data                86.012  15.105195  70.402597   \n",
       "                     avg_d_RH               NaN        NaN        NaN   \n",
       "                     avg_d_precip           NaN        NaN        NaN   \n",
       "                     avg_d_tmp              NaN        NaN        NaN   \n",
       "                     avg_d_wind             NaN        NaN        NaN   \n",
       "...                                         ...        ...        ...   \n",
       "(64.9631, -19.0208)  data                93.813  -1.909459  77.459459   \n",
       "                     avg_d_RH               NaN        NaN        NaN   \n",
       "                     avg_d_precip           NaN        NaN        NaN   \n",
       "                     avg_d_tmp              NaN        NaN        NaN   \n",
       "                     avg_d_wind             NaN        NaN        NaN   \n",
       "\n",
       "                                   avg_m_precip  avg_m_wind  Max_Cases  \\\n",
       "coordinate           information                                         \n",
       "(-41.4545, 145.9707) data                   0.0   18.087013       89.0   \n",
       "                     avg_d_RH               NaN         NaN        NaN   \n",
       "                     avg_d_precip           NaN         NaN        NaN   \n",
       "                     avg_d_tmp              NaN         NaN        NaN   \n",
       "                     avg_d_wind             NaN         NaN        NaN   \n",
       "...                                         ...         ...        ...   \n",
       "(64.9631, -19.0208)  data                   0.0   17.535135     1586.0   \n",
       "                     avg_d_RH               NaN         NaN        NaN   \n",
       "                     avg_d_precip           NaN         NaN        NaN   \n",
       "                     avg_d_tmp              NaN         NaN        NaN   \n",
       "                     avg_d_wind             NaN         NaN        NaN   \n",
       "\n",
       "                                    first_7  ... 3/29/2020 3/30/2020  \\\n",
       "coordinate           information             ...                       \n",
       "(-41.4545, 145.9707) data          1.000000  ...      66.0      66.0   \n",
       "                     avg_d_RH           NaN  ...      85.0      80.0   \n",
       "                     avg_d_precip       NaN  ...       0.0       0.0   \n",
       "                     avg_d_tmp          NaN  ...      15.6      14.8   \n",
       "                     avg_d_wind         NaN  ...      14.5      24.9   \n",
       "...                                     ...  ...       ...       ...   \n",
       "(64.9631, -19.0208)  data          1.588235  ...    1020.0    1086.0   \n",
       "                     avg_d_RH           NaN  ...      61.0      63.0   \n",
       "                     avg_d_precip       NaN  ...       0.0       0.0   \n",
       "                     avg_d_tmp          NaN  ...       6.5       6.2   \n",
       "                     avg_d_wind         NaN  ...      31.3      31.4   \n",
       "\n",
       "                                  3/31/2020  4/1/2020  4/2/2020  4/3/2020  \\\n",
       "coordinate           information                                            \n",
       "(-41.4545, 145.9707) data              69.0      69.0      72.0      74.0   \n",
       "                     avg_d_RH          76.0      78.0      96.0      86.0   \n",
       "                     avg_d_precip       0.0       0.0       0.0       0.0   \n",
       "                     avg_d_tmp         12.4      15.1      14.0      15.2   \n",
       "                     avg_d_wind        18.0      12.0      14.8      20.5   \n",
       "...                                     ...       ...       ...       ...   \n",
       "(64.9631, -19.0208)  data            1135.0    1220.0    1319.0    1364.0   \n",
       "                     avg_d_RH          65.0      73.0      79.0      81.0   \n",
       "                     avg_d_precip       0.0       0.0       0.0       0.0   \n",
       "                     avg_d_tmp          6.4      -1.4      -3.1      -6.5   \n",
       "                     avg_d_wind        25.9      17.5      21.6       9.3   \n",
       "\n",
       "                                   4/4/2020  4/5/2020  4/6/2020  4/7/2020  \n",
       "coordinate           information                                           \n",
       "(-41.4545, 145.9707) data              80.0      82.0      86.0      89.0  \n",
       "                     avg_d_RH          82.0      77.0      71.0      74.0  \n",
       "                     avg_d_precip       0.0       0.0       0.0       0.0  \n",
       "                     avg_d_tmp         13.0       6.7       9.0      10.3  \n",
       "                     avg_d_wind        18.7      17.4      11.3       8.0  \n",
       "...                                     ...       ...       ...       ...  \n",
       "(64.9631, -19.0208)  data            1417.0    1486.0    1562.0    1586.0  \n",
       "                     avg_d_RH          78.0      85.0      77.0      57.0  \n",
       "                     avg_d_precip       0.0       0.0       0.0       0.0  \n",
       "                     avg_d_tmp         -6.6      -4.3       1.4       0.7  \n",
       "                     avg_d_wind        29.0      26.4      17.3      26.8  \n",
       "\n",
       "[5350 rows x 95 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopkins_conf = pd.DataFrame()\n",
    "with open(PICKLE_PATH, 'rb') as file:\n",
    "#     hopkins_conf = pickle.load(file) # old pandas versions use this line to load pickle file\n",
    "    hopkins_conf = pd.read_pickle(file) # updated pandas versions use this line to load pickle file\n",
    "hopkins_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Preliminary checks on imported data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df dimensions: (5350, 95)\n",
      "Number of 'data' rows: 1070\n",
      "Number of 'data' rows with NaN Country_Region: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking that our starting data has no nan country_region entries in 'data' rows\n",
    "print('Original df dimensions: {}'.format(hopkins_conf.shape))\n",
    "check = pd.DataFrame(hopkins_conf.xs('data', level='information', axis=0))\n",
    "print('Number of \\'data\\' rows: {}'.format(check.shape[0]))\n",
    "check = check[check['Country_Region'].isna()]\n",
    "print('Number of \\'data\\' rows with NaN Country_Region: {}'.format(check.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Load external datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GDP BY COUNTRY ========\n",
    "# source: https://data.worldbank.org/indicator/NY.GDP.PCAP.CD  - in current USD\n",
    "gdp_country_path = '../external_datasets/GDP_per_capita_countries.csv'\n",
    "gdp_country = pd.read_csv(gdp_country_path)\n",
    "gdp_country.columns=['Country_Region', 'GDP']\n",
    "\n",
    "\n",
    "# ========== US STATES GDP ========\n",
    "# source: https://en.wikipedia.org/wiki/List_of_U.S._states_by_GDP_per_capita#cite_note-3\n",
    "# source: https://www.statista.com/statistics/248023/us-gross-domestic-product-gdp-by-state/ \n",
    "gdp_us_state_path = '../external_datasets/GDP_per_capita_states.csv'\n",
    "gdp_us_state = pd.read_csv(gdp_us_state_path)\n",
    "gdp_us_state.columns = ['Province_State', 'GDP']\n",
    "\n",
    "\n",
    "# ========== CHINA PROVINCES GDP ========\n",
    "#source: https://en.wikipedia.org/wiki/List_of_Chinese_administrative_divisions_by_GDP_per_capita\n",
    "gdp_china_province_path = '../external_datasets/GDP_per_capita_china_provinces.csv'\n",
    "gdp_china_province = pd.read_csv(gdp_china_province_path)\n",
    "gdp_china_province.columns = ['Province_State', 'GDP']\n",
    "\n",
    "\n",
    "# ========== GDP US STATES AND CHINA PROVINCES APPENDED ======== # for convenience\n",
    "gdp_all_provinces = gdp_us_state.append(gdp_china_province, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# ========== URBANIZATION BY COUNTRY ========\n",
    "# source: http://wdi.worldbank.org/table/4.2# (2018)\n",
    "urban_country_path = '../external_datasets/urbanization_data.csv'\n",
    "urban_country = pd.read_csv(urban_country_path)\n",
    "urban_country.columns=['Country_Region', 'Urbanization']\n",
    "\n",
    "\n",
    "# ========== US STATES URBANIZATION ========\n",
    "# source: US census bureau (most updated was is from 2010)\n",
    "urban_us_state_path = '../external_datasets/urbanization_states.csv'\n",
    "urban_us_state = pd.read_csv(urban_us_state_path)\n",
    "urban_us_state.columns = ['Province_State', 'Urbanization']\n",
    "\n",
    "\n",
    "# ========== CHINA PROVINCES URBANIZATION ========\n",
    "# source: https://en.wikipedia.org/wiki/Urbanization_in_China\n",
    "urban_china_province_path = '../external_datasets/urbanization_china_provinces.csv'\n",
    "urban_china_province = pd.read_csv(urban_china_province_path)\n",
    "urban_china_province.columns = ['Province_State', 'Urbanization']\n",
    "\n",
    "\n",
    "# ========== URBANIZATION US STATES AND CHINA PROVINCES APPENDED ======== # for convenience\n",
    "urban_all_provinces = urban_us_state.append(urban_china_province, ignore_index=True)\n",
    "\n",
    "\n",
    "# ========== MEDIAN AGE BY COUNTRY========\n",
    "# source: https://ourworldindata.org/grapher/median-age?year=2020&time=2020\n",
    "median_age_per_countries_2020_path = '../external_datasets/median_age_per_countries_2020.csv'\n",
    "median_age_per_countries_2020 = pd.read_csv(median_age_per_countries_2020_path)\n",
    "median_age_per_countries_2020.columns = ['Country_Region', 'code', 'year', 'Median Age']\n",
    "median_age_per_countries_2020 = median_age_per_countries_2020.drop(['code'], axis = 1)\n",
    "median_age_per_countries_2020 = median_age_per_countries_2020[(median_age_per_countries_2020['year'] == 2020) & (median_age_per_countries_2020['Country_Region'] != 'United States')]\n",
    "median_age_per_countries_2020 = median_age_per_countries_2020.drop(['year'], axis = 1)\n",
    "\n",
    "\n",
    "# ========== US STATES MEDIAN AGE ========\n",
    "# source: https://worldpopulationreview.com/states/median-age-by-state/\n",
    "median_age_per_US_state_2020_path = '../external_datasets/median_age_per_US_state_2020.csv'\n",
    "median_age_state_col_list = ['State', 'MedianAge']\n",
    "median_age_per_US_state_2020 = pd.read_csv(median_age_per_US_state_2020_path, usecols = median_age_state_col_list)\n",
    "median_age_per_US_state_2020.columns = ['Province_State', 'Median Age']\n",
    "\n",
    "\n",
    "# ========== DEMOCRACY INDEX BY COUNTRY ========\n",
    "# source: https://en.wikipedia.org/wiki/Democracy_Index#cite_note-index2019-7\n",
    "democracy_index_by_country_path = '../external_datasets/democracy_index_by_country.csv'\n",
    "democracy_col_list = ['Country', 'Score']\n",
    "democracy_index_by_country = pd.read_csv(democracy_index_by_country_path, usecols = democracy_col_list)\n",
    "democracy_index_by_country.columns = ['Country_Region', 'Democracy']\n",
    "\n",
    "\n",
    "# ========== DAILY TESTS ADMINISTERED US STATES ========\n",
    "d_tests_us_states_path = '../external_datasets/US_daily_tests_filtered.csv'\n",
    "d_tests_us_states_df = pd.read_csv(d_tests_us_states_path)\n",
    "target_cols = ['date', 'state', 'total']\n",
    "d_tests_us_states_df = d_tests_us_states_df[target_cols]\n",
    "\n",
    "\n",
    "# ========== POPULATION PER STATE ========\n",
    "us_states_population_path = '../external_datasets/population_us_states.csv'\n",
    "us_states_population = pd.read_csv(us_states_population_path)\n",
    "us_states_population.columns = ['Province_State', 'State Pop']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Filling missing data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments describe missing data and sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GDP ========\n",
    "\n",
    "# Virgin Islands source: https://www.macrotrends.net/countries/VIR/virgin-islands-us/gdp-per-capita\n",
    "missing_GDP_per_US_territory_values = {\n",
    "    'Province_State': ['American Samoa', 'Guam', 'Northern Mariana Islands', 'Puerto Rico', 'Virgin Islands'], \n",
    "    'GDP': [11466.69071, 35712.56214, 23258.67586, 31651.34815, 35938]\n",
    "}\n",
    "\n",
    "missing_GDP_per_US_territory_df = pd.DataFrame.from_dict(missing_GDP_per_US_territory_values)\n",
    "gdp_all_provinces = gdp_all_provinces.append(missing_GDP_per_US_territory_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# ========== MEDIAN AGE ========\n",
    "\n",
    "# Missing info (excluding Northern Mariana Islands) from median_age_per_countries_2020_path (were not listed as US states)\n",
    "# Missing info for Northern Mariana Islands from https://en.wikipedia.org/wiki/List_of_countries_by_median_age\n",
    "missing_median_age_per_US_territory_values = {\n",
    "    'Province_State': ['American Samoa', 'Guam', 'Northern Mariana Islands', 'Puerto Rico', 'Virgin Islands'], \n",
    "    'Median Age': [22, 31.4, 33.6, 38.2, 42.2]\n",
    "}\n",
    "\n",
    "# Missing info from https://en.wikipedia.org/wiki/List_of_countries_by_median_age\n",
    "# the 'US' entry is based on (37.0902, -95.7129) which is Kansas\n",
    "# 'Holy See' - the Vatican. Was given the medain age in Italy\n",
    "missing_median_age_per_country_values = {\n",
    "    'Country_Region': ['East Timor', 'Congo (Kinshasa)', 'Congo (Brazzaville)', 'Dominica', 'Andorra', 'Kosovo', 'Liechtenstein', \n",
    "                       'San Marino', 'Monaco', 'Saint Kitts and Nevis', 'US', 'Holy See'], \n",
    "    'Median Age': [18.9, 18.6, 19.7, 33.5, 44.3, 29.1, 43.2, 44.4, 53.1, 35, 36.5, 47.9]\n",
    "}\n",
    "\n",
    "# Appending missing \"Median Age\" values \n",
    "missing_median_ages_per_US_state_df = pd.DataFrame.from_dict(missing_median_age_per_US_territory_values)\n",
    "median_age_per_US_state_2020 = median_age_per_US_state_2020.append(missing_median_ages_per_US_state_df, ignore_index=True)\n",
    "\n",
    "missing_median_ages_per_country_df = pd.DataFrame.from_dict(missing_median_age_per_country_values)\n",
    "median_age_per_countries_2020 = median_age_per_countries_2020.append(missing_median_ages_per_country_df, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# ========== DEMOCRACY INDEX BY COUNTRY ========\n",
    "\n",
    "### Missing info from https://en.wikipedia.org/wiki/List_of_freedom_indices & https://www.transparency.org/cpi2019\n",
    "# Saint Vincent and the Grenadines (7.9, based on corruption between South Korea and Cabo Verde)\n",
    "# Seychelles (7.9, based on corruption between Chile and Taiwan)\n",
    "# Sao Tome and Principe (6.8, based on corruption between Croatia and Argentina)\n",
    "# Maldives (4, based on corruption between Guinea and Mexico)\n",
    "# Brunei (7.16, based on corruption of Malaysia)\n",
    "# Somalia (1, based on corruption index last 3 years)\n",
    "# Holy See (7.52, same as Italy)\n",
    "# Grenada (7.3, based on corruption between Italy and Malaysia)\n",
    "# Belize (7.02, based on list of freedoms indices)\n",
    "# Dominica (7.78, \")\n",
    "# Monaco (8.12, same as France)\n",
    "# Barbados (6.2, based on CORRUPTION PERCEPTIONS INDEX 2019 https://www.transparency.org/cpi2019)\n",
    "# Bahamas (6.4, \")\n",
    "# Saint Lucia (5.5, \")\n",
    "# Kosovo (3.6, \")\n",
    "# Andorra (7.3, based on list of freedoms indices - like Grenada)\n",
    "# Antigua and Barbuda (\")\n",
    "# Saint Kitts and Nevis (\")\n",
    "# Liechtenstein (\")\n",
    "# Western Sahara (3, based on list of freedoms indices)\n",
    "# San Marino (7.5, considered as fairly democratic. Based on https://news.un.org/en/story/2013/04/435902-world-can-learn-san-marinos-democratic-system-says-un-chief)\n",
    "missing_democracy_values = {\n",
    "    'Country_Region': ['Saint Vincent and the Grenadines', 'Seychelles', 'Sao Tome and Principe', 'Maldives', 'Brunei', \n",
    "                       'Somalia', 'Holy See', 'Grenada', 'Belize', 'Dominica', 'Monaco', 'Barbados', 'Bahamas', 'Saint Lucia', \n",
    "                       'Kosovo', 'Andorra', 'Antigua and Barbuda', 'Saint Kitts and Nevis', 'Liechtenstein', 'Western Sahara', 'San Marino'],\n",
    "    'Democracy': [7.9, 7.9, 6.8, 4, 7.16, 1, 7.52, 7.3, 7.02, 7.78, 8.12, 6.2, 6.4, 5.5, 3.6, 7.3, 7.3, 7.3, 7.3, 3, 7.5]\n",
    "}\n",
    "\n",
    "# Appending missing \"Democracy\" values \n",
    "missing_democracy_values_df = pd.DataFrame.from_dict(missing_democracy_values)\n",
    "democracy_index_by_country = democracy_index_by_country.append(missing_democracy_values_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Translation Dictionaries_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to Standardize names in original df and external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_us_states_names(df):\n",
    "    df = df.replace({\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_names(external_df):\n",
    "    external_df = external_df.replace({\n",
    "        'Bahamas, The': 'Bahamas',\n",
    "        'Brunei Darussalam': 'Brunei',\n",
    "        'Cape Verde': 'Cabo Verde',\n",
    "        'Congo, Dem. Rep.': 'Congo (Kinshasa)',\n",
    "        'Congo, Rep.': 'Congo (Brazzaville)',\n",
    "        'Czech Republic':'Czechia',\n",
    "        'Democratic Republic of the Congo': 'Congo (Kinshasa)',\n",
    "        'Egypt, Arab Rep.': 'Egypt',\n",
    "        'Eswatini': 'Swaziland',\n",
    "        'Gambia, The': 'Gambia',\n",
    "        'Iran, Islamic Rep.': 'Iran',\n",
    "        'Ivory Coast': 'Cote d\\'Ivoire',\n",
    "        'Korea, Rep.': 'Korea, South',\n",
    "        'Kyrgyz Republic': 'Kyrgyzstan',\n",
    "        'Macedonia': 'North Macedonia',\n",
    "        'Myanmar': 'Burma',\n",
    "        'Palestine': 'West Bank and Gaza',\n",
    "        'Republic of the Congo': 'Congo (Brazzaville)',\n",
    "        'Russian Federation': 'Russia',\n",
    "        'Slovak Republic': 'Slovakia',\n",
    "        'South Korea': 'Korea, South',\n",
    "        'South Korea[n 2]': 'Korea, South',        \n",
    "        'St. Kitts and Nevis': 'Saint Kitts and Nevis',\n",
    "        'St. Lucia': 'Saint Lucia',\n",
    "        'St. Vincent and the Grenadines': 'Saint Vincent and the Grenadines',\n",
    "        'Syrian Arab Republic': 'Syria',\n",
    "        'Taiwan*': 'Taiwan',\n",
    "        'Timor Leste': 'East Timor',\n",
    "        'Timor-Leste': 'East Timor',\n",
    "        'United States': 'US',\n",
    "        'Venezuela, RB': 'Venezuela'\n",
    "       })\n",
    "    return external_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# was used for standardizaing China province names\n",
    "def china_check(urban_or_gdp):\n",
    "    check = hopkins_conf[hopkins_conf['Country_Region']=='China']\n",
    "    china_original_prov = set(check['Province_State'])\n",
    "    china_gdp_prov = set(gdp_china_province.Province_State)\n",
    "\n",
    "    orig_minus_gdp = china_original_prov.difference(china_gdp_prov)\n",
    "    gdp_minus_orig = china_gdp_prov.difference(china_original_prov)\n",
    "\n",
    "    china_original_prov = sorted(set(check['Province_State']))\n",
    "    china_gdp_prov = sorted(set(gdp_china_province.Province_State))\n",
    "\n",
    "    test_list = [china_gdp_prov, china_original_prov]\n",
    "    for x, y in zip(*test_list): \n",
    "        print(x, y) # print(test_list)\n",
    "\n",
    "    print('orig_minus_gdp: {}'.format(orig_minus_gdp))\n",
    "    print('gdp_minus_orig: {}'.format(gdp_minus_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Functions for adding US States daily tests data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_index(df, row_name, gap=5):\n",
    "    \"\"\"\n",
    "    Adds a row on level 1 of a df\n",
    "    \"\"\"\n",
    "    idx = df.index\n",
    "    previous_coor = (0,0)\n",
    "    i = gap\n",
    "    for coor, data in df.iterrows():\n",
    "        coor = coor[0]\n",
    "        if coor != previous_coor:\n",
    "            idx = idx.insert(i, (coor, row_name))\n",
    "            i += (gap + 1)\n",
    "            previous_coor = coor\n",
    "    return df.copy().reindex(idx)\n",
    "\n",
    "def convert_dates(df_old):\n",
    "    df_new = df_old.copy()\n",
    "    df_new['date'] = df_new.apply(lambda row: datetime.datetime.strptime(str(row['date']), '%Y%m%d'), axis=1)\n",
    "    return df_new\n",
    "\n",
    "\n",
    "def add_daily_tests(df, tests_data):\n",
    "    coordinates = set(df.index.get_level_values(level=0).tolist())\n",
    "    common_dates = set(tests_data.index.get_level_values(level=0)).intersection(set(df.columns))\n",
    "    counter = 0\n",
    "    return_df = df.copy()\n",
    "    for coor in coordinates:\n",
    "        if counter % 50 == 0:\n",
    "            print(counter)\n",
    "        counter += 1\n",
    "        if return_df.loc[coor].loc['data']['Country_Region']=='US':\n",
    "            state = return_df.loc[coor].loc['data']['Province_State']\n",
    "#             for (date,state) in tests_data.index:\n",
    "            for date in common_dates:\n",
    "                if (date,state) in tests_data.index:\n",
    "#                 if date in common_dates:\n",
    "#                     return_df.loc[coor,date]['d_tests'] = tests_data.loc[(date, state)]['d_tests']\n",
    "                    return_df.loc[(coor, 'd_tests'),date] = tests_data.loc[(date, state)]['d_tests']\n",
    "#                     print('State: {}, date: {}, d_tests: {}'.format(state, date,tests_data.loc[(date, state)]['d_tests']))\n",
    "    return return_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing for daily tests US states data\n",
    "\n",
    "# convert dates formats\n",
    "d_tests_us_states_df = convert_dates(d_tests_us_states_df)\n",
    "# standardize names\n",
    "d_tests_us_states_df = standardize_us_states_names(d_tests_us_states_df)\n",
    "d_tests_us_states_df.sort_values(['state', 'date'], inplace=True)\n",
    "# count daily from cumulated totals\n",
    "d_tests_us_states_df['d_tests'] = d_tests_us_states_df.groupby(['state'])['total'].transform(lambda x: x.diff()) \n",
    "d_tests_us_states_df['date'] = d_tests_us_states_df.apply(lambda row: \\\n",
    "                            datetime.datetime.strftime(datetime.datetime.strptime(str(row['date']), '%Y-%m-%d %H:%M:%S'), '%-m/%-d/%Y'), axis=1)\n",
    "\n",
    "us_states_population = standardize_us_states_names(us_states_population)\n",
    "us_states_population = us_states_population.set_index('Province_State')\n",
    "\n",
    "\n",
    "# add total tests divided by total population column\n",
    "d_tests_us_states_df['total_tests_div_pop'] = d_tests_us_states_df.apply(lambda row: (row['total']/us_states_population.loc[row['state']]), axis=1)\n",
    "\n",
    "# set multi index\n",
    "d_tests_us_states_df = d_tests_us_states_df.set_index(['date','state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATE_POP_PKL_PATH = '../external_datasets/state_pop.pkl'\n",
    "# with open(STATE_POP_PKL_PATH, 'wb') as file:\n",
    "#     pickle.dump(new_hopkins_conf, file)\n",
    "    \n",
    "    \n",
    "# TOTAL_TESTS_PKL_PATH = '../external_datasets/total_tests.pkl'\n",
    "# with open(TOTAL_TESTS_PKL_PATH, 'wb') as file:\n",
    "#     pickle.dump(new_hopkins_conf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003042104264880889"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(d_tests_us_states_df.xs('Alabama', level='state').loc[max_date])['total_tests_div_pop']\n",
    "# df.xs('Ai', level='name', drop_level=False)\n",
    "# d_tests_us_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>d_tests</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3/7/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/8/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/9/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/10/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/11/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/12/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>65.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/13/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>73.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/14/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>94.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/15/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>127.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/16/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>170.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/17/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>215.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/18/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>266.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/19/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>332.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/20/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>416.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/21/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>442.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/22/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>459.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/23/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>552.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/24/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/25/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>725.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/26/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>871.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/27/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>1038.0</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/28/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>10920.0</td>\n",
       "      <td>9882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>12385.0</td>\n",
       "      <td>1465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>14235.0</td>\n",
       "      <td>1850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>15941.0</td>\n",
       "      <td>1706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>17427.0</td>\n",
       "      <td>1486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>19683.0</td>\n",
       "      <td>2256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>21470.0</td>\n",
       "      <td>1787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>24905.0</td>\n",
       "      <td>3435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>27249.0</td>\n",
       "      <td>2344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>29835.0</td>\n",
       "      <td>2586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/7/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>31969.0</td>\n",
       "      <td>2134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/8/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>34110.0</td>\n",
       "      <td>2141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/9/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>38494.0</td>\n",
       "      <td>4384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/10/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>40740.0</td>\n",
       "      <td>2246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/11/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>43172.0</td>\n",
       "      <td>2432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/12/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>45200.0</td>\n",
       "      <td>2028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/13/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>45428.0</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/14/2020</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>47978.0</td>\n",
       "      <td>2550.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      total  d_tests\n",
       "date      state                     \n",
       "3/7/2020  Missouri      0.0      NaN\n",
       "3/8/2020  Missouri      1.0      1.0\n",
       "3/9/2020  Missouri      1.0      0.0\n",
       "3/10/2020 Missouri      1.0      0.0\n",
       "3/11/2020 Missouri      1.0      0.0\n",
       "3/12/2020 Missouri     65.0     64.0\n",
       "3/13/2020 Missouri     73.0      8.0\n",
       "3/14/2020 Missouri     94.0     21.0\n",
       "3/15/2020 Missouri    127.0     33.0\n",
       "3/16/2020 Missouri    170.0     43.0\n",
       "3/17/2020 Missouri    215.0     45.0\n",
       "3/18/2020 Missouri    266.0     51.0\n",
       "3/19/2020 Missouri    332.0     66.0\n",
       "3/20/2020 Missouri    416.0     84.0\n",
       "3/21/2020 Missouri    442.0     26.0\n",
       "3/22/2020 Missouri    459.0     17.0\n",
       "3/23/2020 Missouri    552.0     93.0\n",
       "3/24/2020 Missouri    552.0      0.0\n",
       "3/25/2020 Missouri    725.0    173.0\n",
       "3/26/2020 Missouri    871.0    146.0\n",
       "3/27/2020 Missouri   1038.0    167.0\n",
       "3/28/2020 Missouri  10920.0   9882.0\n",
       "3/29/2020 Missouri  12385.0   1465.0\n",
       "3/30/2020 Missouri  14235.0   1850.0\n",
       "3/31/2020 Missouri  15941.0   1706.0\n",
       "4/1/2020  Missouri  17427.0   1486.0\n",
       "4/2/2020  Missouri  19683.0   2256.0\n",
       "4/3/2020  Missouri  21470.0   1787.0\n",
       "4/4/2020  Missouri  24905.0   3435.0\n",
       "4/5/2020  Missouri  27249.0   2344.0\n",
       "4/6/2020  Missouri  29835.0   2586.0\n",
       "4/7/2020  Missouri  31969.0   2134.0\n",
       "4/8/2020  Missouri  34110.0   2141.0\n",
       "4/9/2020  Missouri  38494.0   4384.0\n",
       "4/10/2020 Missouri  40740.0   2246.0\n",
       "4/11/2020 Missouri  43172.0   2432.0\n",
       "4/12/2020 Missouri  45200.0   2028.0\n",
       "4/13/2020 Missouri  45428.0    228.0\n",
       "4/14/2020 Missouri  47978.0   2550.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tests_us_states_df.iloc[d_tests_us_states_df.index.get_level_values('state') == 'Missouri']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _this is where the magic happens_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROVINCE_STATE = 'Province_State'\n",
    "COUNTRY_REGION = 'Country_Region'\n",
    "DAILY_TESTS = 'd_tests'\n",
    "MAX_DATE = '4/7/2020'\n",
    "\n",
    "\n",
    "def add_gdp_urban(original_df, args_datasets):\n",
    "    \n",
    "    # import argument dataframes from input dict\n",
    "    gdp_country = args_datasets['gdp_country']\n",
    "    gdp_all_provinces = args_datasets['gdp_all_provinces'] \n",
    "    urban_country = args_datasets['urban_country']\n",
    "    urban_all_provinces = args_datasets['urban_all_provinces'] \n",
    "    median_age_per_countries_2020 = args_datasets['median_age_per_countries_2020']\n",
    "    median_age_per_US_state_2020 = args_datasets['median_age_per_US_state_2020']\n",
    "    democracy_index_by_country = args_datasets['democracy_index_by_country']\n",
    "    d_tests_us_states_df = args_datasets['d_tests_us_states_df']\n",
    "    us_states_population = args_datasets['us_states_population']\n",
    "    \n",
    "\n",
    "    \n",
    "    # standardizing region names\n",
    "    result = standardize_names(original_df)\n",
    "    gdp_country = standardize_names(gdp_country)\n",
    "    urban_country = standardize_names(urban_country)\n",
    "    median_age_per_countries_2020 = standardize_names(median_age_per_countries_2020)\n",
    "    democracy_index_by_country = standardize_names(democracy_index_by_country)\n",
    "\n",
    "    \n",
    "    # setting indices for more convenient access in lambda funtion below\n",
    "    gdp_country = gdp_country.set_index(COUNTRY_REGION)\n",
    "    gdp_all_provinces = gdp_all_provinces.set_index(PROVINCE_STATE)\n",
    "    urban_country = urban_country.set_index(COUNTRY_REGION)\n",
    "    urban_all_provinces = urban_all_provinces.set_index(PROVINCE_STATE)\n",
    "    median_age_per_US_state_2020 = median_age_per_US_state_2020.set_index(PROVINCE_STATE)\n",
    "    median_age_per_countries_2020 = median_age_per_countries_2020.set_index(COUNTRY_REGION)\n",
    "    democracy_index_by_country = democracy_index_by_country.set_index(COUNTRY_REGION)\n",
    "\n",
    "\n",
    "#     if there is no state data, take country data, and if there is also no country data, put NaN\n",
    "    result['GDP'] = result.apply(lambda row: gdp_all_provinces.loc[row[PROVINCE_STATE],'GDP'] \\\n",
    "                                     if row[PROVINCE_STATE] in list(gdp_all_provinces.index) \\\n",
    "                                     else (gdp_country.loc[row[COUNTRY_REGION],'GDP'] \\\n",
    "                                           if row[COUNTRY_REGION] in list(gdp_country.index) \\\n",
    "                                           else np.NaN), axis=1) \n",
    "    \n",
    "    result['Urbanization'] = result.apply(lambda row: urban_all_provinces.loc[row[PROVINCE_STATE],'Urbanization'] \\\n",
    "                                              if row[PROVINCE_STATE] in list(urban_all_provinces.index) \\\n",
    "                                              else (urban_country.loc[row[COUNTRY_REGION],'Urbanization'] \\\n",
    "                                                    if row[COUNTRY_REGION] in list(urban_country.index) \\\n",
    "                                                    else np.NaN), axis=1)\n",
    "    \n",
    "    result['Median Age'] = result.apply(lambda row: median_age_per_US_state_2020.loc[row[PROVINCE_STATE],'Median Age'] \\\n",
    "                                            if row[PROVINCE_STATE] in list(median_age_per_US_state_2020.index) \\\n",
    "                                            else (median_age_per_countries_2020.loc[row[COUNTRY_REGION], 'Median Age'] \\\n",
    "                                                  if row[COUNTRY_REGION] in list(median_age_per_countries_2020.index) \\\n",
    "                                                  else np.NaN), axis=1)\n",
    "    \n",
    "    result['Democracy'] = result.apply(lambda row: democracy_index_by_country.loc[row[COUNTRY_REGION], 'Democracy'] \\\n",
    "                                           if row[COUNTRY_REGION] in list(democracy_index_by_country.index) \\\n",
    "                                           else np.NaN, axis=1)\n",
    "    \n",
    "    \n",
    "    result['State Population'] = result.apply(lambda row: us_states_population.loc[row[PROVINCE_STATE]]['State Pop'] \\\n",
    "                                              if row[PROVINCE_STATE] in list(us_states_population.index) \\\n",
    "                                              else np.NaN, axis = 1)\n",
    "    \n",
    "    result['Total Tests'] = result.apply(lambda row: (d_tests_us_states_df.xs(row[PROVINCE_STATE], level='state').loc[max_date])['total']\n",
    "                                              if row[PROVINCE_STATE] in list(us_states_population.index) \\\n",
    "                                              else np.NaN, axis = 1)\n",
    "    \n",
    "    \n",
    "    result['Tests \\ Pop'] = result.apply(lambda row: (d_tests_us_states_df.xs(row[PROVINCE_STATE], level='state').loc[max_date])['total_tests_div_pop']\n",
    "                                              if row[PROVINCE_STATE] in list(us_states_population.index) \\\n",
    "                                              else np.NaN, axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # adding daily_tests administered field to index level 1\n",
    "    result = add_index(result,DAILY_TESTS)\n",
    "\n",
    "    # adding tests administered per data per US State\n",
    "    result = add_daily_tests(result, d_tests_us_states_df)\n",
    "    \n",
    "    # reordering columns\n",
    "    new_columns = list(result.columns)\n",
    "\n",
    "    prev_GDP = new_columns.index('GDP')\n",
    "    prev_urban = new_columns.index('Urbanization')\n",
    "    prev_median_age = new_columns.index('Median Age')\n",
    "    prev_democracy = new_columns.index('Democracy')\n",
    "    prev_state_pop = new_columns.index('State Population')\n",
    "    prev_total_tests = new_columns.index('Total Tests')\n",
    "    prev_tests_div_pop = new_columns.index('Tests \\ Pop')\n",
    "\n",
    "    new_GDP = new_columns.index(COUNTRY_REGION) + 1\n",
    "    new_urban = new_GDP + 1\n",
    "    new_median_age = new_urban + 1\n",
    "    new_democracy = new_median_age + 1\n",
    "    new_state_pop = new_democracy + 1\n",
    "    new_total_tests = new_state_pop + 1\n",
    "    new_tests_div_pop = new_total_tests +1\n",
    "\n",
    "    new_columns.insert(new_GDP, new_columns.pop(prev_GDP))\n",
    "    new_columns.insert(new_urban, new_columns.pop(prev_urban))\n",
    "    new_columns.insert(new_median_age, new_columns.pop(prev_median_age))\n",
    "    new_columns.insert(new_democracy, new_columns.pop(prev_democracy))\n",
    "    new_columns.insert(new_state_pop, new_columns.pop(prev_state_pop))\n",
    "    new_columns.insert(new_total_tests, new_columns.pop(prev_total_tests))\n",
    "    new_columns.insert(new_tests_div_pop, new_columns.pop(prev_tests_div_pop))\n",
    "\n",
    "    return result[new_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Democracy</th>\n",
       "      <th>State Population</th>\n",
       "      <th>Total Tests</th>\n",
       "      <th>Tests \\ Pop</th>\n",
       "      <th>avg_m_tmp</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinate</th>\n",
       "      <th>information</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">(-41.4545, 145.9707)</th>\n",
       "      <th>data</th>\n",
       "      <td>Tasmania</td>\n",
       "      <td>Australia</td>\n",
       "      <td>57373.68668</td>\n",
       "      <td>86.012</td>\n",
       "      <td>37.900002</td>\n",
       "      <td>9.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.105195</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_RH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_precip</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_tmp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_wind</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">(64.9631, -19.0208)</th>\n",
       "      <th>avg_d_RH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_precip</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_tmp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_wind</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>31.3</td>\n",
       "      <td>31.4</td>\n",
       "      <td>25.9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>21.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>17.3</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_tests</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6420 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Province_State Country_Region          GDP  \\\n",
       "coordinate           information                                               \n",
       "(-41.4545, 145.9707) data               Tasmania      Australia  57373.68668   \n",
       "                     avg_d_RH                NaN            NaN          NaN   \n",
       "                     avg_d_precip            NaN            NaN          NaN   \n",
       "                     avg_d_tmp               NaN            NaN          NaN   \n",
       "                     avg_d_wind              NaN            NaN          NaN   \n",
       "...                                          ...            ...          ...   \n",
       "(64.9631, -19.0208)  avg_d_RH                NaN            NaN          NaN   \n",
       "                     avg_d_precip            NaN            NaN          NaN   \n",
       "                     avg_d_tmp               NaN            NaN          NaN   \n",
       "                     avg_d_wind              NaN            NaN          NaN   \n",
       "                     d_tests                 NaN            NaN          NaN   \n",
       "\n",
       "                                   Urbanization  Median Age Democracy  \\\n",
       "coordinate           information                                        \n",
       "(-41.4545, 145.9707) data                86.012   37.900002      9.09   \n",
       "                     avg_d_RH               NaN         NaN       NaN   \n",
       "                     avg_d_precip           NaN         NaN       NaN   \n",
       "                     avg_d_tmp              NaN         NaN       NaN   \n",
       "                     avg_d_wind             NaN         NaN       NaN   \n",
       "...                                         ...         ...       ...   \n",
       "(64.9631, -19.0208)  avg_d_RH               NaN         NaN       NaN   \n",
       "                     avg_d_precip           NaN         NaN       NaN   \n",
       "                     avg_d_tmp              NaN         NaN       NaN   \n",
       "                     avg_d_wind             NaN         NaN       NaN   \n",
       "                     d_tests                NaN         NaN       NaN   \n",
       "\n",
       "                                   State Population  Total Tests  Tests \\ Pop  \\\n",
       "coordinate           information                                                \n",
       "(-41.4545, 145.9707) data                       NaN          NaN          NaN   \n",
       "                     avg_d_RH                   NaN          NaN          NaN   \n",
       "                     avg_d_precip               NaN          NaN          NaN   \n",
       "                     avg_d_tmp                  NaN          NaN          NaN   \n",
       "                     avg_d_wind                 NaN          NaN          NaN   \n",
       "...                                             ...          ...          ...   \n",
       "(64.9631, -19.0208)  avg_d_RH                   NaN          NaN          NaN   \n",
       "                     avg_d_precip               NaN          NaN          NaN   \n",
       "                     avg_d_tmp                  NaN          NaN          NaN   \n",
       "                     avg_d_wind                 NaN          NaN          NaN   \n",
       "                     d_tests                    NaN          NaN          NaN   \n",
       "\n",
       "                                   avg_m_tmp  ...  3/29/2020  3/30/2020  \\\n",
       "coordinate           information              ...                         \n",
       "(-41.4545, 145.9707) data          15.105195  ...       66.0       66.0   \n",
       "                     avg_d_RH            NaN  ...       85.0       80.0   \n",
       "                     avg_d_precip        NaN  ...        0.0        0.0   \n",
       "                     avg_d_tmp           NaN  ...       15.6       14.8   \n",
       "                     avg_d_wind          NaN  ...       14.5       24.9   \n",
       "...                                      ...  ...        ...        ...   \n",
       "(64.9631, -19.0208)  avg_d_RH            NaN  ...       61.0       63.0   \n",
       "                     avg_d_precip        NaN  ...        0.0        0.0   \n",
       "                     avg_d_tmp           NaN  ...        6.5        6.2   \n",
       "                     avg_d_wind          NaN  ...       31.3       31.4   \n",
       "                     d_tests             NaN  ...        NaN        NaN   \n",
       "\n",
       "                                   3/31/2020  4/1/2020  4/2/2020 4/3/2020  \\\n",
       "coordinate           information                                            \n",
       "(-41.4545, 145.9707) data               69.0      69.0      72.0     74.0   \n",
       "                     avg_d_RH           76.0      78.0      96.0     86.0   \n",
       "                     avg_d_precip        0.0       0.0       0.0      0.0   \n",
       "                     avg_d_tmp          12.4      15.1      14.0     15.2   \n",
       "                     avg_d_wind         18.0      12.0      14.8     20.5   \n",
       "...                                      ...       ...       ...      ...   \n",
       "(64.9631, -19.0208)  avg_d_RH           65.0      73.0      79.0     81.0   \n",
       "                     avg_d_precip        0.0       0.0       0.0      0.0   \n",
       "                     avg_d_tmp           6.4      -1.4      -3.1     -6.5   \n",
       "                     avg_d_wind         25.9      17.5      21.6      9.3   \n",
       "                     d_tests             NaN       NaN       NaN      NaN   \n",
       "\n",
       "                                  4/4/2020 4/5/2020  4/6/2020  4/7/2020  \n",
       "coordinate           information                                         \n",
       "(-41.4545, 145.9707) data             80.0     82.0      86.0      89.0  \n",
       "                     avg_d_RH         82.0     77.0      71.0      74.0  \n",
       "                     avg_d_precip      0.0      0.0       0.0       0.0  \n",
       "                     avg_d_tmp        13.0      6.7       9.0      10.3  \n",
       "                     avg_d_wind       18.7     17.4      11.3       8.0  \n",
       "...                                    ...      ...       ...       ...  \n",
       "(64.9631, -19.0208)  avg_d_RH         78.0     85.0      77.0      57.0  \n",
       "                     avg_d_precip      0.0      0.0       0.0       0.0  \n",
       "                     avg_d_tmp        -6.6     -4.3       1.4       0.7  \n",
       "                     avg_d_wind       29.0     26.4      17.3      26.8  \n",
       "                     d_tests           NaN      NaN       NaN       NaN  \n",
       "\n",
       "[6420 rows x 100 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_datasets = {\n",
    "    'gdp_country': gdp_country, \n",
    "    'gdp_all_provinces': gdp_all_provinces, \n",
    "    'urban_country': urban_country, \n",
    "    'urban_all_provinces': urban_all_provinces, \n",
    "    'median_age_per_countries_2020': median_age_per_countries_2020, \n",
    "    'median_age_per_US_state_2020': median_age_per_US_state_2020, \n",
    "    'democracy_index_by_country': democracy_index_by_country,\n",
    "    'd_tests_us_states_df': d_tests_us_states_df,\n",
    "    'us_states_population': us_states_population\n",
    "}\n",
    "new_hopkins_conf = add_gdp_urban(hopkins_conf, args_datasets)\n",
    "\n",
    "new_hopkins_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Some tests_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Democracy</th>\n",
       "      <th>State Population</th>\n",
       "      <th>Total Tests</th>\n",
       "      <th>Tests \\ Pop</th>\n",
       "      <th>avg_m_tmp</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Province_State, Country_Region, GDP, Urbanization, Median Age, Democracy, State Population, Total Tests, Tests \\ Pop, avg_m_tmp, avg_m_RH, avg_m_precip, avg_m_wind, Max_Cases, first_7, last relevant date, Max_Date, 5%_Date, avg_interval_tmp, avg_interval_RH, GF_Q1, GF_Q2, GF_Q3, 1/22/2020, 1/23/2020, 1/24/2020, 1/25/2020, 1/26/2020, 1/27/2020, 1/28/2020, 1/29/2020, 1/30/2020, 1/31/2020, 2/1/2020, 2/2/2020, 2/3/2020, 2/4/2020, 2/5/2020, 2/6/2020, 2/7/2020, 2/8/2020, 2/9/2020, 2/10/2020, 2/11/2020, 2/12/2020, 2/13/2020, 2/14/2020, 2/15/2020, 2/16/2020, 2/17/2020, 2/18/2020, 2/19/2020, 2/20/2020, 2/21/2020, 2/22/2020, 2/23/2020, 2/24/2020, 2/25/2020, 2/26/2020, 2/27/2020, 2/28/2020, 2/29/2020, 3/1/2020, 3/2/2020, 3/3/2020, 3/4/2020, 3/5/2020, 3/6/2020, 3/7/2020, 3/8/2020, 3/9/2020, 3/10/2020, 3/11/2020, 3/12/2020, 3/13/2020, 3/14/2020, 3/15/2020, 3/16/2020, 3/17/2020, 3/18/2020, 3/19/2020, 3/20/2020, 3/21/2020, 3/22/2020, 3/23/2020, 3/24/2020, 3/25/2020, 3/26/2020, 3/27/2020, 3/28/2020, 3/29/2020, 3/30/2020, 3/31/2020, 4/1/2020, 4/2/2020, 4/3/2020, 4/4/2020, 4/5/2020, 4/6/2020, 4/7/2020]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 100 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_test = pd.DataFrame(new_hopkins_conf.xs('data', level='information', axis=0))\n",
    "age_test = age_test[age_test['Median Age'].isna()]\n",
    "age_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Democracy</th>\n",
       "      <th>State Population</th>\n",
       "      <th>Total Tests</th>\n",
       "      <th>Tests \\ Pop</th>\n",
       "      <th>avg_m_tmp</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Province_State, Country_Region, GDP, Urbanization, Median Age, Democracy, State Population, Total Tests, Tests \\ Pop, avg_m_tmp, avg_m_RH, avg_m_precip, avg_m_wind, Max_Cases, first_7, last relevant date, Max_Date, 5%_Date, avg_interval_tmp, avg_interval_RH, GF_Q1, GF_Q2, GF_Q3, 1/22/2020, 1/23/2020, 1/24/2020, 1/25/2020, 1/26/2020, 1/27/2020, 1/28/2020, 1/29/2020, 1/30/2020, 1/31/2020, 2/1/2020, 2/2/2020, 2/3/2020, 2/4/2020, 2/5/2020, 2/6/2020, 2/7/2020, 2/8/2020, 2/9/2020, 2/10/2020, 2/11/2020, 2/12/2020, 2/13/2020, 2/14/2020, 2/15/2020, 2/16/2020, 2/17/2020, 2/18/2020, 2/19/2020, 2/20/2020, 2/21/2020, 2/22/2020, 2/23/2020, 2/24/2020, 2/25/2020, 2/26/2020, 2/27/2020, 2/28/2020, 2/29/2020, 3/1/2020, 3/2/2020, 3/3/2020, 3/4/2020, 3/5/2020, 3/6/2020, 3/7/2020, 3/8/2020, 3/9/2020, 3/10/2020, 3/11/2020, 3/12/2020, 3/13/2020, 3/14/2020, 3/15/2020, 3/16/2020, 3/17/2020, 3/18/2020, 3/19/2020, 3/20/2020, 3/21/2020, 3/22/2020, 3/23/2020, 3/24/2020, 3/25/2020, 3/26/2020, 3/27/2020, 3/28/2020, 3/29/2020, 3/30/2020, 3/31/2020, 4/1/2020, 4/2/2020, 4/3/2020, 4/4/2020, 4/5/2020, 4/6/2020, 4/7/2020]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 100 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_test = pd.DataFrame(new_hopkins_conf.xs('data', level='information', axis=0))\n",
    "dem_test = dem_test[dem_test['Democracy'].isna()]\n",
    "dem_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Democracy</th>\n",
       "      <th>State Population</th>\n",
       "      <th>Total Tests</th>\n",
       "      <th>Tests \\ Pop</th>\n",
       "      <th>avg_m_tmp</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinate</th>\n",
       "      <th>information</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Province_State, Country_Region, GDP, Urbanization, Median Age, Democracy, State Population, Total Tests, Tests \\ Pop, avg_m_tmp, avg_m_RH, avg_m_precip, avg_m_wind, Max_Cases, first_7, last relevant date, Max_Date, 5%_Date, avg_interval_tmp, avg_interval_RH, GF_Q1, GF_Q2, GF_Q3, 1/22/2020, 1/23/2020, 1/24/2020, 1/25/2020, 1/26/2020, 1/27/2020, 1/28/2020, 1/29/2020, 1/30/2020, 1/31/2020, 2/1/2020, 2/2/2020, 2/3/2020, 2/4/2020, 2/5/2020, 2/6/2020, 2/7/2020, 2/8/2020, 2/9/2020, 2/10/2020, 2/11/2020, 2/12/2020, 2/13/2020, 2/14/2020, 2/15/2020, 2/16/2020, 2/17/2020, 2/18/2020, 2/19/2020, 2/20/2020, 2/21/2020, 2/22/2020, 2/23/2020, 2/24/2020, 2/25/2020, 2/26/2020, 2/27/2020, 2/28/2020, 2/29/2020, 3/1/2020, 3/2/2020, 3/3/2020, 3/4/2020, 3/5/2020, 3/6/2020, 3/7/2020, 3/8/2020, 3/9/2020, 3/10/2020, 3/11/2020, 3/12/2020, 3/13/2020, 3/14/2020, 3/15/2020, 3/16/2020, 3/17/2020, 3/18/2020, 3/19/2020, 3/20/2020, 3/21/2020, 3/22/2020, 3/23/2020, 3/24/2020, 3/25/2020, 3/26/2020, 3/27/2020, 3/28/2020, 3/29/2020, 3/30/2020, 3/31/2020, 4/1/2020, 4/2/2020, 4/3/2020, 4/4/2020, 4/5/2020, 4/6/2020, 4/7/2020]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 100 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = new_hopkins_conf[new_hopkins_conf['Urbanization'].isna()]\n",
    "check = check[check['Country_Region'].notna()]\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Democracy</th>\n",
       "      <th>State Population</th>\n",
       "      <th>Total Tests</th>\n",
       "      <th>Tests \\ Pop</th>\n",
       "      <th>avg_m_tmp</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinate</th>\n",
       "      <th>information</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Province_State, Country_Region, GDP, Urbanization, Median Age, Democracy, State Population, Total Tests, Tests \\ Pop, avg_m_tmp, avg_m_RH, avg_m_precip, avg_m_wind, Max_Cases, first_7, last relevant date, Max_Date, 5%_Date, avg_interval_tmp, avg_interval_RH, GF_Q1, GF_Q2, GF_Q3, 1/22/2020, 1/23/2020, 1/24/2020, 1/25/2020, 1/26/2020, 1/27/2020, 1/28/2020, 1/29/2020, 1/30/2020, 1/31/2020, 2/1/2020, 2/2/2020, 2/3/2020, 2/4/2020, 2/5/2020, 2/6/2020, 2/7/2020, 2/8/2020, 2/9/2020, 2/10/2020, 2/11/2020, 2/12/2020, 2/13/2020, 2/14/2020, 2/15/2020, 2/16/2020, 2/17/2020, 2/18/2020, 2/19/2020, 2/20/2020, 2/21/2020, 2/22/2020, 2/23/2020, 2/24/2020, 2/25/2020, 2/26/2020, 2/27/2020, 2/28/2020, 2/29/2020, 3/1/2020, 3/2/2020, 3/3/2020, 3/4/2020, 3/5/2020, 3/6/2020, 3/7/2020, 3/8/2020, 3/9/2020, 3/10/2020, 3/11/2020, 3/12/2020, 3/13/2020, 3/14/2020, 3/15/2020, 3/16/2020, 3/17/2020, 3/18/2020, 3/19/2020, 3/20/2020, 3/21/2020, 3/22/2020, 3/23/2020, 3/24/2020, 3/25/2020, 3/26/2020, 3/27/2020, 3/28/2020, 3/29/2020, 3/30/2020, 3/31/2020, 4/1/2020, 4/2/2020, 4/3/2020, 4/4/2020, 4/5/2020, 4/6/2020, 4/7/2020]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 100 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = new_hopkins_conf[new_hopkins_conf['GDP'].isna()]\n",
    "check = check[check['Country_Region'].notna()]\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique GDP values for US states: 55\n",
      "Unique Urbanization values for US states: 55\n"
     ]
    }
   ],
   "source": [
    "gdp = len(new_hopkins_conf[new_hopkins_conf[COUNTRY_REGION]=='US']['GDP'].unique())\n",
    "print('Unique GDP values for US states: {}'.format(gdp))\n",
    "\n",
    "urb = len(new_hopkins_conf[new_hopkins_conf[COUNTRY_REGION]=='US']['Urbanization'].unique())\n",
    "print('Unique Urbanization values for US states: {}'.format(urb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df data rows dimensions: (1070, 95)\n",
      "New df data rows dimensions: (1070, 100)\n"
     ]
    }
   ],
   "source": [
    "# Checking that our starting data has no nan country_region entries in 'data' rows\n",
    "check_old = pd.DataFrame(hopkins_conf.xs('data', level='information', axis=0)).shape\n",
    "print('Original df data rows dimensions: {}'.format(check_old))\n",
    "\n",
    "check_new = pd.DataFrame(new_hopkins_conf.xs('data', level='information', axis=0)).shape\n",
    "print('New df data rows dimensions: {}'.format(check_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_d_tests(df, tests_data):\n",
    "    tests_data_dates = tests_data.index.get_level_values(level=0)\n",
    "    common_dates = set(tests_data_dates).intersection(set(df.columns))\n",
    "    printed = []\n",
    "    dict = {}\n",
    "    coords = set(df.index.get_level_values(level=0).tolist())\n",
    "    for coord in coords:\n",
    "        if df.loc[coord].loc['data']['Country_Region']=='US':\n",
    "            state = df.loc[coord].loc['data']['Province_State']\n",
    "            if not (state in printed):\n",
    "                printed.append(state)\n",
    "#                 print(state)\n",
    "#                 print(coord)\n",
    "#                 print(df.loc[coord].loc['d_tests'][common_dates].tolist())\n",
    "                dict[state] = pd.DataFrame(df.loc[coord][common_dates])\n",
    "    return dict\n",
    "\n",
    "test_dict = test_d_tests(new_hopkins_conf, d_tests_us_states_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3/8/2020</th>\n",
       "      <th>3/19/2020</th>\n",
       "      <th>3/9/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/23/2020</th>\n",
       "      <th>3/27/2020</th>\n",
       "      <th>3/16/2020</th>\n",
       "      <th>3/12/2020</th>\n",
       "      <th>3/11/2020</th>\n",
       "      <th>...</th>\n",
       "      <th>3/20/2020</th>\n",
       "      <th>3/6/2020</th>\n",
       "      <th>3/21/2020</th>\n",
       "      <th>3/17/2020</th>\n",
       "      <th>3/7/2020</th>\n",
       "      <th>3/14/2020</th>\n",
       "      <th>3/28/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>3/24/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>103.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>97.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_RH</th>\n",
       "      <td>94.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>93.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>88.00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>97.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_precip</th>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>84.07</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.88</td>\n",
       "      <td>22.35</td>\n",
       "      <td>6.35</td>\n",
       "      <td>26.92</td>\n",
       "      <td>18.54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_tmp</th>\n",
       "      <td>0.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_d_wind</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.30</td>\n",
       "      <td>6.00</td>\n",
       "      <td>15.60</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>15.20</td>\n",
       "      <td>8.80</td>\n",
       "      <td>10.40</td>\n",
       "      <td>17.20</td>\n",
       "      <td>15.90</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_tests</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>254.00</td>\n",
       "      <td>4833.00</td>\n",
       "      <td>1065.00</td>\n",
       "      <td>13560.00</td>\n",
       "      <td>873.0</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>10933.00</td>\n",
       "      <td>31900.00</td>\n",
       "      <td>1254.00</td>\n",
       "      <td>673.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              3/8/2020  3/19/2020  3/9/2020  4/5/2020  3/29/2020  3/23/2020  \\\n",
       "information                                                                   \n",
       "data               5.0        9.0      7.00    103.00      53.00      12.00   \n",
       "avg_d_RH          94.0       77.0     86.00     93.00      91.00      88.00   \n",
       "avg_d_precip       3.3        0.0      0.76     84.07       3.81       1.02   \n",
       "avg_d_tmp          0.3        4.1      1.70     -1.20       0.80       2.10   \n",
       "avg_d_wind         7.6        3.2      3.50      9.30       6.00      15.60   \n",
       "d_tests           19.0     1119.0    254.00   4833.00    1065.00   13560.00   \n",
       "\n",
       "              3/27/2020  3/16/2020  3/12/2020  3/11/2020  ...  3/20/2020  \\\n",
       "information                                               ...              \n",
       "data               30.0        5.0        7.0        7.0  ...        9.0   \n",
       "avg_d_RH           62.0       97.0       39.0       62.0  ...       76.0   \n",
       "avg_d_precip        0.0        0.0        0.0        0.0  ...        0.0   \n",
       "avg_d_tmp           0.3        0.8       16.1       11.6  ...        5.9   \n",
       "avg_d_wind          8.2        0.4        7.6        5.3  ...        3.4   \n",
       "d_tests           873.0     7107.0       45.0      250.0  ...     1776.0   \n",
       "\n",
       "              3/6/2020  3/21/2020  3/17/2020  3/7/2020  3/14/2020  3/28/2020  \\\n",
       "information                                                                    \n",
       "data               5.0        9.0        5.0      5.00       7.00      41.00   \n",
       "avg_d_RH          66.0       61.0       93.0     95.00      97.00      83.00   \n",
       "avg_d_precip       0.0        0.0        0.0     23.88      22.35       6.35   \n",
       "avg_d_tmp          7.9        8.4        1.4      0.30       2.40       0.10   \n",
       "avg_d_wind        18.2        4.0        2.4     15.20       8.80      10.40   \n",
       "d_tests            7.0     1041.0      148.0      9.00      50.00   10933.00   \n",
       "\n",
       "              4/4/2020  3/24/2020  4/1/2020  \n",
       "information                                  \n",
       "data             97.00      20.00      78.0  \n",
       "avg_d_RH         85.00      94.00      74.0  \n",
       "avg_d_precip     26.92      18.54       0.0  \n",
       "avg_d_tmp         0.50      -1.20       3.2  \n",
       "avg_d_wind       17.20      15.90      12.9  \n",
       "d_tests       31900.00    1254.00     673.0  \n",
       "\n",
       "[6 rows x 40 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_state = 'California'\n",
    "\n",
    "test_dict[test_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>3/4/2020</th>\n",
       "      <th>3/5/2020</th>\n",
       "      <th>3/6/2020</th>\n",
       "      <th>3/7/2020</th>\n",
       "      <th>3/8/2020</th>\n",
       "      <th>3/9/2020</th>\n",
       "      <th>3/10/2020</th>\n",
       "      <th>3/11/2020</th>\n",
       "      <th>3/12/2020</th>\n",
       "      <th>3/13/2020</th>\n",
       "      <th>...</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "      <th>4/8/2020</th>\n",
       "      <th>4/9/2020</th>\n",
       "      <th>4/10/2020</th>\n",
       "      <th>4/11/2020</th>\n",
       "      <th>4/12/2020</th>\n",
       "      <th>4/13/2020</th>\n",
       "      <th>4/14/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>...</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "      <th>California</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>515.000000</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>531.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>804.00000</td>\n",
       "      <td>823.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>131533.000000</td>\n",
       "      <td>132431.000000</td>\n",
       "      <td>145329.000000</td>\n",
       "      <td>158864.000000</td>\n",
       "      <td>177600.000000</td>\n",
       "      <td>178763.000000</td>\n",
       "      <td>185276.000000</td>\n",
       "      <td>203528.000000</td>\n",
       "      <td>204082.000000</td>\n",
       "      <td>215408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d_tests</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>254.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4833.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>12898.000000</td>\n",
       "      <td>13535.000000</td>\n",
       "      <td>18736.000000</td>\n",
       "      <td>1163.000000</td>\n",
       "      <td>6513.000000</td>\n",
       "      <td>18252.000000</td>\n",
       "      <td>554.000000</td>\n",
       "      <td>11326.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_tests_div_pop</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.005452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                   3/4/2020    3/5/2020    3/6/2020    3/7/2020  \\\n",
       "state                California  California  California  California   \n",
       "total                515.000000  515.000000  522.000000  531.000000   \n",
       "d_tests                     NaN    0.000000    7.000000    9.000000   \n",
       "total_tests_div_pop    0.000013    0.000013    0.000013    0.000013   \n",
       "\n",
       "date                   3/8/2020   3/9/2020   3/10/2020    3/11/2020  \\\n",
       "state                California California  California   California   \n",
       "total                550.000000  804.00000  823.000000  1073.000000   \n",
       "d_tests               19.000000  254.00000   19.000000   250.000000   \n",
       "total_tests_div_pop    0.000014    0.00002    0.000021     0.000027   \n",
       "\n",
       "date                   3/12/2020    3/13/2020  ...       4/5/2020  \\\n",
       "state                 California   California  ...     California   \n",
       "total                1118.000000  1118.000000  ...  131533.000000   \n",
       "d_tests                45.000000     0.000000  ...    4833.000000   \n",
       "total_tests_div_pop     0.000028     0.000028  ...       0.003329   \n",
       "\n",
       "date                      4/6/2020       4/7/2020       4/8/2020  \\\n",
       "state                   California     California     California   \n",
       "total                132431.000000  145329.000000  158864.000000   \n",
       "d_tests                 898.000000   12898.000000   13535.000000   \n",
       "total_tests_div_pop       0.003352       0.003678       0.004021   \n",
       "\n",
       "date                      4/9/2020      4/10/2020      4/11/2020  \\\n",
       "state                   California     California     California   \n",
       "total                177600.000000  178763.000000  185276.000000   \n",
       "d_tests               18736.000000    1163.000000    6513.000000   \n",
       "total_tests_div_pop       0.004495       0.004524       0.004689   \n",
       "\n",
       "date                     4/12/2020      4/13/2020      4/14/2020  \n",
       "state                   California     California     California  \n",
       "total                203528.000000  204082.000000  215408.000000  \n",
       "d_tests               18252.000000     554.000000   11326.000000  \n",
       "total_tests_div_pop       0.005151       0.005165       0.005452  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tests_us_states_df.iloc[d_tests_us_states_df.index.get_level_values('state') == test_state].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique values does a given date have? \n",
    "# we expect the number of states or less because of repetitions\n",
    "test_date = '4/5/2020'\n",
    "idx = pd.IndexSlice\n",
    "len(new_hopkins_conf.loc[idx[:, 'd_tests'], :][test_date].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Democracy</th>\n",
       "      <th>State Population</th>\n",
       "      <th>Total Tests</th>\n",
       "      <th>Tests \\ Pop</th>\n",
       "      <th>avg_m_tmp</th>\n",
       "      <th>...</th>\n",
       "      <th>3/29/2020</th>\n",
       "      <th>3/30/2020</th>\n",
       "      <th>3/31/2020</th>\n",
       "      <th>4/1/2020</th>\n",
       "      <th>4/2/2020</th>\n",
       "      <th>4/3/2020</th>\n",
       "      <th>4/4/2020</th>\n",
       "      <th>4/5/2020</th>\n",
       "      <th>4/6/2020</th>\n",
       "      <th>4/7/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinate</th>\n",
       "      <th>information</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(13.4443, 144.7937)</th>\n",
       "      <th>data</th>\n",
       "      <td>Guam</td>\n",
       "      <td>US</td>\n",
       "      <td>35712.56214</td>\n",
       "      <td>94.780</td>\n",
       "      <td>31.4</td>\n",
       "      <td>7.96</td>\n",
       "      <td>165718.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>26.877922</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(18.2208, -66.5901)</th>\n",
       "      <th>data</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>31651.34815</td>\n",
       "      <td>93.578</td>\n",
       "      <td>38.2</td>\n",
       "      <td>7.96</td>\n",
       "      <td>3193694.0</td>\n",
       "      <td>5507.0</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>25.748052</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(18.3358, -64.8963)</th>\n",
       "      <th>data</th>\n",
       "      <td>Virgin Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>35938.00000</td>\n",
       "      <td>95.721</td>\n",
       "      <td>42.2</td>\n",
       "      <td>7.96</td>\n",
       "      <td>104914.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>25.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(19.60121157, -155.5210167)</th>\n",
       "      <th>data</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>US</td>\n",
       "      <td>64096.00000</td>\n",
       "      <td>91.900</td>\n",
       "      <td>38.9</td>\n",
       "      <td>7.96</td>\n",
       "      <td>1415872.0</td>\n",
       "      <td>13542.0</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>14.373611</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(20.86399628, -156.56890969999995)</th>\n",
       "      <th>data</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>US</td>\n",
       "      <td>64096.00000</td>\n",
       "      <td>91.900</td>\n",
       "      <td>38.9</td>\n",
       "      <td>7.96</td>\n",
       "      <td>1415872.0</td>\n",
       "      <td>13542.0</td>\n",
       "      <td>0.009564</td>\n",
       "      <td>22.872727</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(48.29575866, -114.0520569)</th>\n",
       "      <th>data</th>\n",
       "      <td>Montana</td>\n",
       "      <td>US</td>\n",
       "      <td>46609.00000</td>\n",
       "      <td>55.900</td>\n",
       "      <td>39.8</td>\n",
       "      <td>7.96</td>\n",
       "      <td>1068778.0</td>\n",
       "      <td>6985.0</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(48.48171488, -121.766131)</th>\n",
       "      <th>data</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>74182.00000</td>\n",
       "      <td>84.100</td>\n",
       "      <td>37.6</td>\n",
       "      <td>7.96</td>\n",
       "      <td>7614893.0</td>\n",
       "      <td>92434.0</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>5.171429</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(48.82227976, -121.7490018)</th>\n",
       "      <th>data</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>74182.00000</td>\n",
       "      <td>84.100</td>\n",
       "      <td>37.6</td>\n",
       "      <td>7.96</td>\n",
       "      <td>7614893.0</td>\n",
       "      <td>92434.0</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>5.274026</td>\n",
       "      <td>...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(61.14998174, -149.14269860000005)</th>\n",
       "      <th>data</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>US</td>\n",
       "      <td>73205.00000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.96</td>\n",
       "      <td>731545.0</td>\n",
       "      <td>6913.0</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>-7.811688</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(64.80726247, -146.5692662)</th>\n",
       "      <th>data</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>US</td>\n",
       "      <td>73205.00000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.96</td>\n",
       "      <td>731545.0</td>\n",
       "      <td>6913.0</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>-16.824675</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>870 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Province_State Country_Region  \\\n",
       "coordinate                         information                                  \n",
       "(13.4443, 144.7937)                data                   Guam             US   \n",
       "(18.2208, -66.5901)                data            Puerto Rico             US   \n",
       "(18.3358, -64.8963)                data         Virgin Islands             US   \n",
       "(19.60121157, -155.5210167)        data                 Hawaii             US   \n",
       "(20.86399628, -156.56890969999995) data                 Hawaii             US   \n",
       "...                                                        ...            ...   \n",
       "(48.29575866, -114.0520569)        data                Montana             US   \n",
       "(48.48171488, -121.766131)         data             Washington             US   \n",
       "(48.82227976, -121.7490018)        data             Washington             US   \n",
       "(61.14998174, -149.14269860000005) data                 Alaska             US   \n",
       "(64.80726247, -146.5692662)        data                 Alaska             US   \n",
       "\n",
       "                                                        GDP  Urbanization  \\\n",
       "coordinate                         information                              \n",
       "(13.4443, 144.7937)                data         35712.56214        94.780   \n",
       "(18.2208, -66.5901)                data         31651.34815        93.578   \n",
       "(18.3358, -64.8963)                data         35938.00000        95.721   \n",
       "(19.60121157, -155.5210167)        data         64096.00000        91.900   \n",
       "(20.86399628, -156.56890969999995) data         64096.00000        91.900   \n",
       "...                                                     ...           ...   \n",
       "(48.29575866, -114.0520569)        data         46609.00000        55.900   \n",
       "(48.48171488, -121.766131)         data         74182.00000        84.100   \n",
       "(48.82227976, -121.7490018)        data         74182.00000        84.100   \n",
       "(61.14998174, -149.14269860000005) data         73205.00000        66.000   \n",
       "(64.80726247, -146.5692662)        data         73205.00000        66.000   \n",
       "\n",
       "                                                Median Age Democracy  \\\n",
       "coordinate                         information                         \n",
       "(13.4443, 144.7937)                data               31.4      7.96   \n",
       "(18.2208, -66.5901)                data               38.2      7.96   \n",
       "(18.3358, -64.8963)                data               42.2      7.96   \n",
       "(19.60121157, -155.5210167)        data               38.9      7.96   \n",
       "(20.86399628, -156.56890969999995) data               38.9      7.96   \n",
       "...                                                    ...       ...   \n",
       "(48.29575866, -114.0520569)        data               39.8      7.96   \n",
       "(48.48171488, -121.766131)         data               37.6      7.96   \n",
       "(48.82227976, -121.7490018)        data               37.6      7.96   \n",
       "(61.14998174, -149.14269860000005) data               34.0      7.96   \n",
       "(64.80726247, -146.5692662)        data               34.0      7.96   \n",
       "\n",
       "                                                State Population  Total Tests  \\\n",
       "coordinate                         information                                  \n",
       "(13.4443, 144.7937)                data                 165718.0        650.0   \n",
       "(18.2208, -66.5901)                data                3193694.0       5507.0   \n",
       "(18.3358, -64.8963)                data                 104914.0        285.0   \n",
       "(19.60121157, -155.5210167)        data                1415872.0      13542.0   \n",
       "(20.86399628, -156.56890969999995) data                1415872.0      13542.0   \n",
       "...                                                          ...          ...   \n",
       "(48.29575866, -114.0520569)        data                1068778.0       6985.0   \n",
       "(48.48171488, -121.766131)         data                7614893.0      92434.0   \n",
       "(48.82227976, -121.7490018)        data                7614893.0      92434.0   \n",
       "(61.14998174, -149.14269860000005) data                 731545.0       6913.0   \n",
       "(64.80726247, -146.5692662)        data                 731545.0       6913.0   \n",
       "\n",
       "                                                Tests \\ Pop  avg_m_tmp  ...  \\\n",
       "coordinate                         information                          ...   \n",
       "(13.4443, 144.7937)                data            0.003922  26.877922  ...   \n",
       "(18.2208, -66.5901)                data            0.001724  25.748052  ...   \n",
       "(18.3358, -64.8963)                data            0.002717  25.875000  ...   \n",
       "(19.60121157, -155.5210167)        data            0.009564  14.373611  ...   \n",
       "(20.86399628, -156.56890969999995) data            0.009564  22.872727  ...   \n",
       "...                                                     ...        ...  ...   \n",
       "(48.29575866, -114.0520569)        data            0.006536   0.163636  ...   \n",
       "(48.48171488, -121.766131)         data            0.012139   5.171429  ...   \n",
       "(48.82227976, -121.7490018)        data            0.012139   5.274026  ...   \n",
       "(61.14998174, -149.14269860000005) data            0.009450  -7.811688  ...   \n",
       "(64.80726247, -146.5692662)        data            0.009450 -16.824675  ...   \n",
       "\n",
       "                                                3/29/2020  3/30/2020  \\\n",
       "coordinate                         information                         \n",
       "(13.4443, 144.7937)                data              56.0       58.0   \n",
       "(18.2208, -66.5901)                data             127.0      174.0   \n",
       "(18.3358, -64.8963)                data              23.0       30.0   \n",
       "(19.60121157, -155.5210167)        data              10.0       12.0   \n",
       "(20.86399628, -156.56890969999995) data              16.0       20.0   \n",
       "...                                                   ...        ...   \n",
       "(48.29575866, -114.0520569)        data               7.0        9.0   \n",
       "(48.48171488, -121.766131)         data              99.0      101.0   \n",
       "(48.82227976, -121.7490018)        data             116.0      116.0   \n",
       "(61.14998174, -149.14269860000005) data              54.0       59.0   \n",
       "(64.80726247, -146.5692662)        data              23.0       28.0   \n",
       "\n",
       "                                                3/31/2020  4/1/2020  4/2/2020  \\\n",
       "coordinate                         information                                  \n",
       "(13.4443, 144.7937)                data              69.0      77.0      82.0   \n",
       "(18.2208, -66.5901)                data             239.0     286.0     316.0   \n",
       "(18.3358, -64.8963)                data              30.0      30.0      30.0   \n",
       "(19.60121157, -155.5210167)        data              15.0      15.0      18.0   \n",
       "(20.86399628, -156.56890969999995) data              25.0      25.0      26.0   \n",
       "...                                                   ...       ...       ...   \n",
       "(48.29575866, -114.0520569)        data              11.0      14.0      18.0   \n",
       "(48.48171488, -121.766131)         data             121.0     128.0     143.0   \n",
       "(48.82227976, -121.7490018)        data             139.0     139.0     175.0   \n",
       "(61.14998174, -149.14269860000005) data              61.0      65.0      67.0   \n",
       "(64.80726247, -146.5692662)        data              30.0      35.0      40.0   \n",
       "\n",
       "                                               4/3/2020 4/4/2020 4/5/2020  \\\n",
       "coordinate                         information                              \n",
       "(13.4443, 144.7937)                data            84.0     93.0    112.0   \n",
       "(18.2208, -66.5901)                data           316.0    452.0    475.0   \n",
       "(18.3358, -64.8963)                data            37.0     40.0     42.0   \n",
       "(19.60121157, -155.5210167)        data            20.0     22.0     22.0   \n",
       "(20.86399628, -156.56890969999995) data            36.0     38.0     43.0   \n",
       "...                                                 ...      ...      ...   \n",
       "(48.29575866, -114.0520569)        data            18.0     20.0     24.0   \n",
       "(48.48171488, -121.766131)         data           153.0    161.0    161.0   \n",
       "(48.82227976, -121.7490018)        data           182.0    199.0    224.0   \n",
       "(61.14998174, -149.14269860000005) data            73.0     81.0     85.0   \n",
       "(64.80726247, -146.5692662)        data            42.0     46.0     53.0   \n",
       "\n",
       "                                                4/6/2020  4/7/2020  \n",
       "coordinate                         information                      \n",
       "(13.4443, 144.7937)                data            113.0     121.0  \n",
       "(18.2208, -66.5901)                data            513.0     573.0  \n",
       "(18.3358, -64.8963)                data             43.0      43.0  \n",
       "(19.60121157, -155.5210167)        data             23.0      23.0  \n",
       "(20.86399628, -156.56890969999995) data             44.0      48.0  \n",
       "...                                                  ...       ...  \n",
       "(48.29575866, -114.0520569)        data             25.0      31.0  \n",
       "(48.48171488, -121.766131)         data            161.0     166.0  \n",
       "(48.82227976, -121.7490018)        data            228.0     238.0  \n",
       "(61.14998174, -149.14269860000005) data             88.0      98.0  \n",
       "(64.80726247, -146.5692662)        data             53.0      65.0  \n",
       "\n",
       "[870 rows x 100 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hopkins_conf[new_hopkins_conf['Country_Region']=='US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Writing results to pickle file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULT_PATH, 'wb') as file:\n",
    "    pickle.dump(new_hopkins_conf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Checking that pickle was written correctly and loads correctly_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                   Province_State Country_Region          GDP  \\\n",
       "coordinate           information                                               \n",
       "(-41.4545, 145.9707) data               Tasmania      Australia  57373.68668   \n",
       "                     avg_d_RH                NaN            NaN          NaN   \n",
       "                     avg_d_precip            NaN            NaN          NaN   \n",
       "                     avg_d_tmp               NaN            NaN          NaN   \n",
       "                     avg_d_wind              NaN            NaN          NaN   \n",
       "...                                          ...            ...          ...   \n",
       "(64.9631, -19.0208)  avg_d_RH                NaN            NaN          NaN   \n",
       "                     avg_d_precip            NaN            NaN          NaN   \n",
       "                     avg_d_tmp               NaN            NaN          NaN   \n",
       "                     avg_d_wind              NaN            NaN          NaN   \n",
       "                     d_tests                 NaN            NaN          NaN   \n",
       "\n",
       "                                   Urbanization  Median Age Democracy  \\\n",
       "coordinate           information                                        \n",
       "(-41.4545, 145.9707) data                86.012   37.900002      9.09   \n",
       "                     avg_d_RH               NaN         NaN       NaN   \n",
       "                     avg_d_precip           NaN         NaN       NaN   \n",
       "                     avg_d_tmp              NaN         NaN       NaN   \n",
       "                     avg_d_wind             NaN         NaN       NaN   \n",
       "...                                         ...         ...       ...   \n",
       "(64.9631, -19.0208)  avg_d_RH               NaN         NaN       NaN   \n",
       "                     avg_d_precip           NaN         NaN       NaN   \n",
       "                     avg_d_tmp              NaN         NaN       NaN   \n",
       "                     avg_d_wind             NaN         NaN       NaN   \n",
       "                     d_tests                NaN         NaN       NaN   \n",
       "\n",
       "                                   State Population  Total Tests  Tests \\ Pop  \\\n",
       "coordinate           information                                                \n",
       "(-41.4545, 145.9707) data                       NaN          NaN          NaN   \n",
       "                     avg_d_RH                   NaN          NaN          NaN   \n",
       "                     avg_d_precip               NaN          NaN          NaN   \n",
       "                     avg_d_tmp                  NaN          NaN          NaN   \n",
       "                     avg_d_wind                 NaN          NaN          NaN   \n",
       "...                                             ...          ...          ...   \n",
       "(64.9631, -19.0208)  avg_d_RH                   NaN          NaN          NaN   \n",
       "                     avg_d_precip               NaN          NaN          NaN   \n",
       "                     avg_d_tmp                  NaN          NaN          NaN   \n",
       "                     avg_d_wind                 NaN          NaN          NaN   \n",
       "                     d_tests                    NaN          NaN          NaN   \n",
       "\n",
       "                                   avg_m_tmp  ...  3/29/2020  3/30/2020  \\\n",
       "coordinate           information              ...                         \n",
       "(-41.4545, 145.9707) data          15.105195  ...       66.0       66.0   \n",
       "                     avg_d_RH            NaN  ...       85.0       80.0   \n",
       "                     avg_d_precip        NaN  ...        0.0        0.0   \n",
       "                     avg_d_tmp           NaN  ...       15.6       14.8   \n",
       "                     avg_d_wind          NaN  ...       14.5       24.9   \n",
       "...                                      ...  ...        ...        ...   \n",
       "(64.9631, -19.0208)  avg_d_RH            NaN  ...       61.0       63.0   \n",
       "                     avg_d_precip        NaN  ...        0.0        0.0   \n",
       "                     avg_d_tmp           NaN  ...        6.5        6.2   \n",
       "                     avg_d_wind          NaN  ...       31.3       31.4   \n",
       "                     d_tests             NaN  ...        NaN        NaN   \n",
       "\n",
       "                                   3/31/2020  4/1/2020  4/2/2020 4/3/2020  \\\n",
       "coordinate           information                                            \n",
       "(-41.4545, 145.9707) data               69.0      69.0      72.0     74.0   \n",
       "                     avg_d_RH           76.0      78.0      96.0     86.0   \n",
       "                     avg_d_precip        0.0       0.0       0.0      0.0   \n",
       "                     avg_d_tmp          12.4      15.1      14.0     15.2   \n",
       "                     avg_d_wind         18.0      12.0      14.8     20.5   \n",
       "...                                      ...       ...       ...      ...   \n",
       "(64.9631, -19.0208)  avg_d_RH           65.0      73.0      79.0     81.0   \n",
       "                     avg_d_precip        0.0       0.0       0.0      0.0   \n",
       "                     avg_d_tmp           6.4      -1.4      -3.1     -6.5   \n",
       "                     avg_d_wind         25.9      17.5      21.6      9.3   \n",
       "                     d_tests             NaN       NaN       NaN      NaN   \n",
       "\n",
       "                                  4/4/2020 4/5/2020  4/6/2020  4/7/2020  \n",
       "coordinate           information                                         \n",
       "(-41.4545, 145.9707) data             80.0     82.0      86.0      89.0  \n",
       "                     avg_d_RH         82.0     77.0      71.0      74.0  \n",
       "                     avg_d_precip      0.0      0.0       0.0       0.0  \n",
       "                     avg_d_tmp        13.0      6.7       9.0      10.3  \n",
       "                     avg_d_wind       18.7     17.4      11.3       8.0  \n",
       "...                                    ...      ...       ...       ...  \n",
       "(64.9631, -19.0208)  avg_d_RH         78.0     85.0      77.0      57.0  \n",
       "                     avg_d_precip      0.0      0.0       0.0       0.0  \n",
       "                     avg_d_tmp        -6.6     -4.3       1.4       0.7  \n",
       "                     avg_d_wind       29.0     26.4      17.3      26.8  \n",
       "                     d_tests           NaN      NaN       NaN       NaN  \n",
       "\n",
       "[6420 rows x 100 columns]>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "with open(RESULT_PATH, 'rb') as file:\n",
    "    test = pd.read_pickle(file)    \n",
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.loc[idx[:, 'd_tests'], :][test_date].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
